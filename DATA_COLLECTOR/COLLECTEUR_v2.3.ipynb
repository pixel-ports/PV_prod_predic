{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PURPOSE :\n",
    "\n",
    "Aller récupérer sur l'API de PVOutput.org les données d'une station cible:\n",
    "- données production \"live\" (cad pas de temps de 5min à 10min sans la météo) ==> Detail_PROD\n",
    "- données d'insolation (cad pas de temps de 5min à 10min sans la météo. Pas complètement clair si correspond exactement extraterestrial radiation) ==> Detail_INSOL\n",
    "- données production quotidienne (somme sur la journée, dispo aussi en mensuel etc. Ajoute un champ (catégoriel) sur la couverture nuageuse) ==> Aggreg_PROD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRINCIPE :\n",
    "\n",
    "Traitement successif des 3 types de requêtes (avec en bonus les carac de l'installation)\n",
    "- Formulation et test de la requêtes\n",
    "- Définition des dates:\n",
    "    - Déterminer la liste des dates maximale\n",
    "    - A partir des logs, déterminer les dates pour lesquelles on a déjà les données\n",
    "    - Etablir la nouvelle liste de dates pour lesquelles on doit requêter (nouvelles dates ou erreurs)\n",
    "- Boucle de requêtes\n",
    "    - Charger le DF sur disque\n",
    "    - Envois requête\n",
    "    - Append des données reçues dans le DF\n",
    "- Exporter les résultat prk et csv)\n",
    "    - Logs\n",
    "    - Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOGS :\n",
    "v2.2 Ajout de la gestion des dates déjà téléchargés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : \n",
    "- le rappel des date dl ne fonctionne pas comme il faut\n",
    "- la borne haute des dates à appelée n'est pas call (exclusif au lieu d'inclusif)\n",
    "- appliquer la refactoriser en fonctions au autres url\n",
    "    - <<Attention ! pr les données aggrégées il va falloir reprendre des choses\n",
    "- convertir les types à la création des df\n",
    "- merge les dates et time en un TS ?\n",
    "\n",
    "- Gestion des limites d'API\n",
    "     - \"Rate limit information can be obtained by setting the HTTP header X-Rate-Limit to 1\" https://pvoutput.org/help.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies et MeP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairie\n",
    "\n",
    "#Divers\n",
    "import requests #Call API\n",
    "import time #Pr avoir dates avec today etc\n",
    "import os #Pr création dossier etc\n",
    "import pandas as pd\n",
    "\n",
    "#Graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en forme du notebook \n",
    "\n",
    "# Nb de ligne à afficher #Uniquement pr Jup Notbook ?\n",
    "# pd.options.display.max_rows=100 \n",
    "\n",
    "# Largeur des cellules #Uniquement pr Jup Notbook ?\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# Mettre en output toutes les sortie d'une cellule\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\" #\"last_expr\"\n",
    "\n",
    "# Avoir une forme de débugger\n",
    "from IPython.core.debugger import Tracer # Plancer Tracer()() dans la fonction permet d'avoir un pas à pas, \"n(ext) line and run this one, c(ontinue) running until next breakpoint, q(uit) the debugger\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Paramètres globaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres génériques des requètes\n",
    "\n",
    "notre_sys_id = '&sid=66192'\n",
    "api_key = '&key=a29f3f9a012ea9da77c829911b595ae7c470362b'\n",
    "target_sys_id = '&sid1=13412'\n",
    "\n",
    "para_gene = notre_sys_id+api_key+target_sys_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bornes dates"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Valeurs pr test (A INVERSER AVEC VALEURS PR PRODUCTION)\n",
    "\n",
    "wait = 1 #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "date_recente = pd.to_datetime('20121115', format=\"%Y%m%d\", errors='coerce')\n",
    "date_ancienne = pd.to_datetime('20121114', format=\"%Y%m%d\", errors='coerce') # C'est la première date à partir de laquelle des données exploitables existent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs pr production\n",
    "\n",
    "wait = 13 #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "date_recente = pd.to_datetime('today')\n",
    "date_ancienne = pd.to_datetime('20121114', format=\"%Y%m%d\", errors='coerce') # C'est la première date à partir de laquelle des données exploitables existent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test du call API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST_CALL_API(url, date=\"20130101\", colonnes=[]):\n",
    "    ''' url, date(opt), colonnes(opt) --> df\n",
    "    url (url sans la date cible), \n",
    "    date (format texte, par défaut 20130101),\n",
    "    colonnes (liste de noms de colonnes)\n",
    "    '''\n",
    "    #Tracer()() \n",
    "    reponse_l = []\n",
    "    \n",
    "    for ligne in requests.get(url+'&d='+date).text.split(';'):\n",
    "        reponse_l.append(ligne.split(','))\n",
    "        \n",
    "    df = pd.DataFrame.from_records(reponse_l)\n",
    "    \n",
    "    if len(colonnes) == df.shape[1]:\n",
    "        df.columns = colonnes\n",
    "\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciation (potenciellement par chargement des données déjà DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHARGEMENT_DONNEES_DISQUE(path, file_name_core, logs_colonnes_l, data_colonnes_l):\n",
    "    '''(path, file_name_core) --> (log_df, data_df)\n",
    "    NB : si les fichiers ne sont pas trouvés, on instancie des df vierges, mais qui ne seront pas écris sur disque ici. Ce sera la fonction d'enregistrement, qui dans la même passe attribues des noms de colonnes\n",
    "    '''\n",
    "    # Dossier\n",
    "    if os.path.exists(path):\n",
    "        print(\"Dossier %s : trouvé\" % path)\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "        print(\"Dossier %s : non trouvé\" % path)\n",
    "\n",
    "    # Fichier de logs :\n",
    "    if os.path.isfile(path + file_name_core +\"_log.pkl\") and os.access(path + file_name_core + \"_log.pkl\", os.R_OK):\n",
    "        print(\"Fichier %s : trouvé et chargé \" % (file_name_core +\"_log.pkl\"))\n",
    "        log_df = pd.read_pickle(path + file_name_core + \"_log.pkl\")\n",
    "    else:\n",
    "        print(\"Fichier %s : non trouvé, un nouveau est instancié\" % (file_name_core +\"_log.pkl\"))\n",
    "        log_df = pd.DataFrame(columns= logs_colonnes_l)\n",
    "        \n",
    "\n",
    "    # Fichier de données :\n",
    "    if os.path.isfile(path + file_name_core +\"_data.pkl\") and os.access(path + file_name_core + \"_data.pkl\", os.R_OK):\n",
    "        print(\"Fichier %s : trouvé et chargé \" % (file_name_core +\"_data.pkl\"))\n",
    "        data_df = pd.read_pickle(path + file_name_core + \"_data.pkl\")\n",
    "    else:\n",
    "        print(\"Fichier %s : non trouvé, un nouveau est instancié\" % (file_name_core +\"_data.pkl\"))\n",
    "        data_df = pd.DataFrame(columns = data_colonnes_l)\n",
    "    \n",
    "    return (log_df, data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création liste de dates à call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNC_DATES_TO_CALL(log_df): #<<ATTENTION a adapter pr données de production aggrégées, dont la requête n'utilise pas la même forme de liste de date\n",
    "    '''log --> dates_requetes_l\n",
    "    '''\n",
    "    \n",
    "    # Instanciation de la liste de date (en str) à paser argument de la requête :\n",
    "    dates_possibles_l = pd.date_range(start= date_ancienne, end= date_recente).strftime('%Y%m%d')\n",
    "    dates_deja_obtenues_l = list(log_df.loc[log_df['Réponse'] == 200, 'Date_cible'])\n",
    "    dates_requetes_l = [date for date in dates_possibles_l if date not in dates_deja_obtenues_l]\n",
    "    #print(\"dates_possibles_l\", type(dates_possibles_l), dates_possibles_l) \n",
    "    #print(\"dates_deja_obtenues_l\", type(dates_deja_obtenues_l), dates_deja_obtenues_l)\n",
    "    #print(\"dates_requetes_l\", type(dates_requetes_l), dates_requetes_l)\n",
    "\n",
    "    # Calcul durée traitement (en heures)\n",
    "    print(\"Il y a déjà %d dates d'obtenues sur %d, soit encore %d dates a obtenir\" % (len(dates_deja_obtenues_l), len(dates_possibles_l), len(dates_requetes_l)))\n",
    "    print(\"Traiter ce batch prendra %.2f heures\" % ((len(dates_requetes_l)*wait)/(60*60)))\n",
    "    \n",
    "    return dates_requetes_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call API en batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNC_CALL_API_JOUR(dates_requetes_l, wait, url, log_df, data_df):\n",
    "    '''(dates_requetes_l, wait, url, log_df, data_df) --> (log_df, data_df) complétés\n",
    "    '''\n",
    "\n",
    "    for date in dates_requetes_l :\n",
    "        #Limitateur débit\n",
    "        time.sleep(wait) #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "\n",
    "        #Envois requête\n",
    "        requete = requests.get(url + '&d=' + date)\n",
    "        \n",
    "        #Affichage live\n",
    "        print(\"Dates en cours: de \", date, \"\\t\",requete.status_code)\n",
    "\n",
    "        #Log des calls\n",
    "        log_df = log_df.append(\n",
    "            dict(\n",
    "                zip(\n",
    "                    log_df.columns, \n",
    "                    [pd.to_datetime('today'), date, requete.status_code]\n",
    "                )\n",
    "            ), \n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "       #Controleur validité réponse\n",
    "        if requete.status_code == 200:\n",
    "            for ligne in requete.text.split(';'):\n",
    "                #Append du df\n",
    "                data_df = data_df.append(\n",
    "                    dict(\n",
    "                        zip(\n",
    "                            data_df, \n",
    "                            (ligne.split(',') + [date]) # Petite trick due à la requête pr l'insolation, qui ne renvoit pas la date (==> on force la présence de la colonne et ici sa valeur)\n",
    "                        )\n",
    "                    ),\n",
    "                    ignore_index=True\n",
    "                )\n",
    "            \n",
    "        \n",
    "    return (log_df, data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement sur disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNC_ENREGISTREMENT_DISQUE(path, file_name_core, log_df, data_df):\n",
    "    '''(path, file_name_core, log_df, data_df) --> Enregistrement de log_df et data_df en pkl et csv dans le dossier spécifié\n",
    "    '''\n",
    "    # Logs\n",
    "    log_df.to_pickle(path + file_name_core + \"_log.pkl\")\n",
    "    log_df.to_csv(path + file_name_core + \"_log.csv\", index= False)\n",
    "    \n",
    "    # Df\n",
    "    data_df.to_pickle(path + file_name_core + \"_data.pkl\")\n",
    "    data_df.to_csv(path + file_name_core + \"_data.csv\", index= False)\n",
    "    \n",
    "    print(\"Fichiers enregistrés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check du df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CHECK_DF(df):\n",
    "    '''df --> Nb de lignes, nb de lignes en double, df.info() et df.head(15) \n",
    "    '''\n",
    "    print(\"nb de ligne : \", len(df))\n",
    "    print(\"nb de ligne en doublons : \", df.duplicated().sum(), \"\\n\")\n",
    "    \n",
    "    df.info()\n",
    "    return df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set de valeur pour débugage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Jeu de variable pr le débugage\n",
    "\n",
    "path = detail_INSOLATION_path\n",
    "file_name_core = detail_INSOLATION_file_name_core\n",
    "logs_colonnes_l = detail_INSOLATION_logs_colonnes_l\n",
    "data_colonnes_l = detail_INSOLATION_data_colonnes_l \n",
    "url = detail_INSOLATION_url"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test du call à l'API pour cette url \n",
    "\n",
    "TEST_CALL_API(url, colonnes = data_colonnes_l)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Chargement des données\n",
    "\n",
    "(log_df, data_df) = CHARGEMENT_DONNEES_DISQUE(path, file_name_core, logs_colonnes_l, data_colonnes_l)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Liste des dates à call\n",
    "\n",
    "dates_requetes_l = FUNC_DATES_TO_CALL(log_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Call API\n",
    "\n",
    "(log_df, data_df) = FUNC_CALL_API_JOUR(dates_requetes_l, wait, url, log_df, data_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Enregistrement sur disque \n",
    "\n",
    "FUNC_ENREGISTREMENT_DISQUE(path, file_name_core, log_df, data_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Check des données\n",
    "\n",
    "CHECK_DF(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détail_PRODUCTION\n",
    "\n",
    "Détail de la production d'un jour (getstatus).\n",
    "Résolution temporelle de 10min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour \"Détails Production\"\n",
    "\n",
    "# Divers\n",
    "detail_PRODUCTION_path = \"./DETAIL_PRODUCTION/\" #Attention à ce fichu / en fin de path ;)\n",
    "detail_PRODUCTION_file_name_core = \"detail_PRODUCTION\"\n",
    "detail_PRODUCTION_logs_colonnes_l = [\"TS_Call\", \"Date_cible\", \"Réponse\"]\n",
    "detail_PRODUCTION_data_colonnes_l  = [\"Date\", \"Time\", \"Energy_Generation\", \"Energy_Efficiency\", \"Instantaneous_Power\", \"Average_Power\", \"Normalised_Output\", \"Energy_Consumption\", \"Power_Consumption\", \"Temperature\", \"Voltage\"] #/ The parameter sid1 is able to retrieve generation data from any system. Consumption data is not returned. The requesting system must have donation mode enabled. \n",
    "\n",
    "# URL\n",
    "detail = '&h=1' #The history parameter returns the entire status for a given date. \n",
    "nb_max = '&limit=288' #Besoin de fixer à la valeur max de 288\n",
    "ordre = '&asc=1'\n",
    "detail_PRODUCTION_url = 'https://pvoutput.org/service/r2/getstatus.jsp?'+detail+nb_max+ordre+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['20121114,08:50,0,0.000,26,NaN,NaN,NaN,NaN,5.8,NaN',\n",
       " '20121114,09:00,5,0.005,32,30,0.028,NaN,NaN,5.8,NaN',\n",
       " '20121114,09:10,11,0.010,46,36,0.033,NaN,NaN,5.8,NaN',\n",
       " '20121114,09:20,23,0.021,80,72,0.067,NaN,NaN,6.1,NaN',\n",
       " '20121114,09:30,38,0.035,96,90,0.083,NaN,NaN,6.1,NaN',\n",
       " '20121114,09:40,55,0.051,140,102,0.094,NaN,NaN,6.1,NaN',\n",
       " '20121114,09:50,84,0.078,237,174,0.161,NaN,NaN,7.2,NaN',\n",
       " '20121114,10:00,146,0.135,467,372,0.344,NaN,NaN,7.2,NaN',\n",
       " '20121114,10:10,226,0.209,495,480,0.444,NaN,NaN,7.2,NaN',\n",
       " '20121114,10:20,311,0.288,519,510,0.472,NaN,NaN,8.4,NaN',\n",
       " '20121114,10:30,400,0.370,545,534,0.494,NaN,NaN,8.4,NaN',\n",
       " '20121114,10:40,493,0.456,571,558,0.517,NaN,NaN,8.4,NaN',\n",
       " '20121114,10:50,589,0.545,589,576,0.533,NaN,NaN,9.8,NaN',\n",
       " '20121114,11:00,689,0.638,606,600,0.556,NaN,NaN,9.8,NaN',\n",
       " '20121114,11:10,792,0.733,622,618,0.572,NaN,NaN,9.8,NaN',\n",
       " '20121114,11:20,897,0.831,631,630,0.583,NaN,NaN,12.2,NaN',\n",
       " '20121114,11:30,1003,0.929,639,636,0.589,NaN,NaN,12.2,NaN',\n",
       " '20121114,11:40,1112,1.030,661,654,0.606,NaN,NaN,12.2,NaN',\n",
       " '20121114,11:50,1223,1.132,665,666,0.617,NaN,NaN,12.2,NaN',\n",
       " '20121114,12:10,1446,1.339,671,669,0.619,NaN,NaN,14.4,NaN',\n",
       " '20121114,12:20,1558,1.443,678,672,0.622,NaN,NaN,14.4,NaN',\n",
       " '20121114,12:30,1672,1.548,677,684,0.633,NaN,NaN,16.3,NaN',\n",
       " '20121114,12:40,1785,1.653,674,678,0.628,NaN,NaN,16.3,NaN',\n",
       " '20121114,12:50,1898,1.757,671,678,0.628,NaN,NaN,16.3,NaN',\n",
       " '20121114,13:00,2010,1.861,671,672,0.622,NaN,NaN,17.6,NaN',\n",
       " '20121114,13:10,2122,1.965,663,672,0.622,NaN,NaN,17.6,NaN',\n",
       " '20121114,13:20,2232,2.067,657,660,0.611,NaN,NaN,17.6,NaN',\n",
       " '20121114,13:30,2341,2.168,654,654,0.606,NaN,NaN,19.0,NaN',\n",
       " '20121114,13:40,2450,2.269,652,654,0.606,NaN,NaN,19.0,NaN',\n",
       " '20121114,13:50,2558,2.369,657,648,0.600,NaN,NaN,19.0,NaN',\n",
       " '20121114,14:00,2669,2.471,687,666,0.617,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:10,2785,2.579,689,696,0.644,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:20,2873,2.660,252,528,0.489,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:30,2912,2.696,156,234,0.217,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:40,2974,2.754,530,372,0.344,NaN,NaN,19.7,NaN',\n",
       " '20121114,14:50,3023,2.799,194,294,0.272,NaN,NaN,19.7,NaN',\n",
       " '20121114,15:00,3055,2.829,176,192,0.178,NaN,NaN,19.7,NaN',\n",
       " '20121114,15:10,3079,2.851,118,144,0.133,NaN,NaN,18.9,NaN',\n",
       " '20121114,15:20,3100,2.870,100,126,0.117,NaN,NaN,18.9,NaN',\n",
       " '20121114,15:30,3124,2.893,205,144,0.133,NaN,NaN,18.9,NaN',\n",
       " '20121114,15:40,3180,2.944,373,336,0.311,NaN,NaN,18.0,NaN',\n",
       " '20121114,15:50,3240,3.000,341,360,0.333,NaN,NaN,18.0,NaN',\n",
       " '20121114,16:00,3293,3.049,303,318,0.294,NaN,NaN,18.0,NaN',\n",
       " '20121114,16:10,3341,3.094,267,288,0.267,NaN,NaN,18.0,NaN',\n",
       " '20121114,16:20,3382,3.131,222,246,0.228,NaN,NaN,17.6,NaN',\n",
       " '20121114,16:30,3417,3.164,184,210,0.194,NaN,NaN,17.6,NaN',\n",
       " '20121114,16:40,3444,3.189,137,162,0.150,NaN,NaN,17.6,NaN',\n",
       " '20121114,16:50,3462,3.206,90,108,0.100,NaN,NaN,17.0,NaN',\n",
       " '20121114,17:00,3474,3.217,42,72,0.067,NaN,NaN,17.0,NaN',\n",
       " '20121114,17:10,3476,3.219,4,12,0.011,NaN,NaN,17.0,NaN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "reponse = requests.get(detail_PRODUCTION_url+'&d='+\"20121114\")\n",
    "reponse.status_code\n",
    "reponse.text.split(';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traitement du batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Energy_Generation</th>\n",
       "      <th>Energy_Efficiency</th>\n",
       "      <th>Instantaneous_Power</th>\n",
       "      <th>Average_Power</th>\n",
       "      <th>Normalised_Output</th>\n",
       "      <th>Energy_Consumption</th>\n",
       "      <th>Power_Consumption</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20130101</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20130101</td>\n",
       "      <td>10:10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130101</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.009</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20130101</td>\n",
       "      <td>10:30</td>\n",
       "      <td>19</td>\n",
       "      <td>0.018</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20130101</td>\n",
       "      <td>10:40</td>\n",
       "      <td>27</td>\n",
       "      <td>0.025</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>0.044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Time Energy_Generation Energy_Efficiency Instantaneous_Power  \\\n",
       "0  20130101  10:00                 0             0.000                  25   \n",
       "1  20130101  10:10                 4             0.004                  25   \n",
       "2  20130101  10:20                10             0.009                  52   \n",
       "3  20130101  10:30                19             0.018                  70   \n",
       "4  20130101  10:40                27             0.025                  34   \n",
       "\n",
       "  Average_Power Normalised_Output Energy_Consumption Power_Consumption  \\\n",
       "0           NaN               NaN                NaN               NaN   \n",
       "1            24             0.022                NaN               NaN   \n",
       "2            36             0.033                NaN               NaN   \n",
       "3            54             0.050                NaN               NaN   \n",
       "4            48             0.044                NaN               NaN   \n",
       "\n",
       "  Temperature Voltage  \n",
       "0         8.6     NaN  \n",
       "1         8.9     NaN  \n",
       "2         8.9     NaN  \n",
       "3         8.9     NaN  \n",
       "4         9.5     NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier ./DETAIL_PRODUCTION/ : trouvé\n",
      "Fichier detail_PRODUCTION_log.pkl : trouvé et chargé \n",
      "Fichier detail_PRODUCTION_data.pkl : trouvé et chargé \n",
      "Il y a déjà 2307 dates d'obtenues sur 2438, soit encore 131 dates a obtenir\n",
      "Traiter ce batch prendra 0.47 heures\n",
      "Dates en cours: de  20121205 \t 400\n",
      "Dates en cours: de  20121206 \t 400\n",
      "Dates en cours: de  20121207 \t 400\n",
      "Dates en cours: de  20121208 \t 400\n",
      "Dates en cours: de  20121209 \t 400\n",
      "Dates en cours: de  20121210 \t 400\n",
      "Dates en cours: de  20121211 \t 400\n",
      "Dates en cours: de  20121212 \t 400\n",
      "Dates en cours: de  20121213 \t 400\n",
      "Dates en cours: de  20121214 \t 400\n",
      "Dates en cours: de  20130313 \t 400\n",
      "Dates en cours: de  20131008 \t 400\n",
      "Dates en cours: de  20131009 \t 400\n",
      "Dates en cours: de  20131010 \t 400\n",
      "Dates en cours: de  20131011 \t 400\n",
      "Dates en cours: de  20131012 \t 400\n",
      "Dates en cours: de  20131013 \t 400\n",
      "Dates en cours: de  20131014 \t 400\n",
      "Dates en cours: de  20141007 \t 400\n",
      "Dates en cours: de  20141008 \t 400\n",
      "Dates en cours: de  20141009 \t 400\n",
      "Dates en cours: de  20141010 \t 400\n",
      "Dates en cours: de  20141211 \t 400\n",
      "Dates en cours: de  20150209 \t 400\n",
      "Dates en cours: de  20150210 \t 400\n",
      "Dates en cours: de  20150211 \t 400\n",
      "Dates en cours: de  20150212 \t 400\n",
      "Dates en cours: de  20150213 \t 400\n",
      "Dates en cours: de  20150214 \t 400\n",
      "Dates en cours: de  20150215 \t 400\n",
      "Dates en cours: de  20150216 \t 400\n",
      "Dates en cours: de  20150217 \t 400\n",
      "Dates en cours: de  20150218 \t 400\n",
      "Dates en cours: de  20150219 \t 400\n",
      "Dates en cours: de  20150220 \t 400\n",
      "Dates en cours: de  20160210 \t 400\n",
      "Dates en cours: de  20160211 \t 400\n",
      "Dates en cours: de  20160212 \t 400\n",
      "Dates en cours: de  20160213 \t 400\n",
      "Dates en cours: de  20160214 \t 400\n",
      "Dates en cours: de  20160215 \t 400\n",
      "Dates en cours: de  20160216 \t 400\n",
      "Dates en cours: de  20160217 \t 400\n",
      "Dates en cours: de  20160218 \t 400\n",
      "Dates en cours: de  20160219 \t 400\n",
      "Dates en cours: de  20160220 \t 400\n",
      "Dates en cours: de  20160221 \t 400\n",
      "Dates en cours: de  20160222 \t 400\n",
      "Dates en cours: de  20160223 \t 400\n",
      "Dates en cours: de  20160224 \t 400\n",
      "Dates en cours: de  20160225 \t 400\n",
      "Dates en cours: de  20190430 \t 200\n",
      "Dates en cours: de  20190501 \t 200\n",
      "Dates en cours: de  20190502 \t 200\n",
      "Dates en cours: de  20190503 \t 200\n",
      "Dates en cours: de  20190504 \t 200\n",
      "Dates en cours: de  20190505 \t 200\n",
      "Dates en cours: de  20190506 \t 200\n",
      "Dates en cours: de  20190507 \t 200\n",
      "Dates en cours: de  20190508 \t 200\n",
      "Dates en cours: de  20190509 \t 200\n",
      "Dates en cours: de  20190510 \t 200\n",
      "Dates en cours: de  20190511 \t 200\n",
      "Dates en cours: de  20190512 \t 200\n",
      "Dates en cours: de  20190513 \t 200\n",
      "Dates en cours: de  20190514 \t 200\n",
      "Dates en cours: de  20190515 \t 200\n",
      "Dates en cours: de  20190516 \t 200\n",
      "Dates en cours: de  20190517 \t 200\n",
      "Dates en cours: de  20190518 \t 200\n",
      "Dates en cours: de  20190519 \t 200\n",
      "Dates en cours: de  20190520 \t 200\n",
      "Dates en cours: de  20190521 \t 200\n",
      "Dates en cours: de  20190522 \t 200\n",
      "Dates en cours: de  20190523 \t 200\n",
      "Dates en cours: de  20190524 \t 200\n",
      "Dates en cours: de  20190525 \t 200\n",
      "Dates en cours: de  20190526 \t 200\n",
      "Dates en cours: de  20190527 \t 200\n",
      "Dates en cours: de  20190528 \t 200\n",
      "Dates en cours: de  20190529 \t 200\n",
      "Dates en cours: de  20190530 \t 200\n",
      "Dates en cours: de  20190531 \t 200\n",
      "Dates en cours: de  20190601 \t 200\n",
      "Dates en cours: de  20190602 \t 200\n",
      "Dates en cours: de  20190603 \t 200\n",
      "Dates en cours: de  20190604 \t 200\n",
      "Dates en cours: de  20190605 \t 200\n",
      "Dates en cours: de  20190606 \t 200\n",
      "Dates en cours: de  20190607 \t 200\n",
      "Dates en cours: de  20190608 \t 200\n",
      "Dates en cours: de  20190609 \t 200\n",
      "Dates en cours: de  20190610 \t 200\n",
      "Dates en cours: de  20190611 \t 200\n",
      "Dates en cours: de  20190612 \t 200\n",
      "Dates en cours: de  20190613 \t 200\n",
      "Dates en cours: de  20190614 \t 200\n",
      "Dates en cours: de  20190615 \t 200\n",
      "Dates en cours: de  20190616 \t 200\n",
      "Dates en cours: de  20190617 \t 200\n",
      "Dates en cours: de  20190618 \t 200\n",
      "Dates en cours: de  20190619 \t 200\n",
      "Dates en cours: de  20190620 \t 200\n",
      "Dates en cours: de  20190621 \t 200\n",
      "Dates en cours: de  20190622 \t 200\n",
      "Dates en cours: de  20190623 \t 200\n",
      "Dates en cours: de  20190624 \t 200\n",
      "Dates en cours: de  20190625 \t 200\n",
      "Dates en cours: de  20190626 \t 200\n",
      "Dates en cours: de  20190627 \t 200\n",
      "Dates en cours: de  20190628 \t 200\n",
      "Dates en cours: de  20190629 \t 200\n",
      "Dates en cours: de  20190630 \t 200\n",
      "Dates en cours: de  20190701 \t 200\n",
      "Dates en cours: de  20190702 \t 200\n",
      "Dates en cours: de  20190703 \t 200\n",
      "Dates en cours: de  20190704 \t 200\n",
      "Dates en cours: de  20190705 \t 200\n",
      "Dates en cours: de  20190706 \t 200\n",
      "Dates en cours: de  20190707 \t 200\n",
      "Dates en cours: de  20190708 \t 200\n",
      "Dates en cours: de  20190709 \t 200\n",
      "Dates en cours: de  20190710 \t 200\n",
      "Dates en cours: de  20190711 \t 200\n",
      "Dates en cours: de  20190712 \t 200\n",
      "Dates en cours: de  20190713 \t 200\n",
      "Dates en cours: de  20190714 \t 200\n",
      "Dates en cours: de  20190715 \t 200\n",
      "Dates en cours: de  20190716 \t 200\n",
      "Dates en cours: de  20190717 \t 200\n",
      "Dates en cours: de  20190718 \t 200\n",
      "Fichiers enregistrés\n",
      "nb de ligne :  267966\n",
      "nb de ligne en doublons :  0 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 267966 entries, 0 to 267965\n",
      "Data columns (total 11 columns):\n",
      "Date                   267966 non-null object\n",
      "Time                   267966 non-null object\n",
      "Energy_Generation      267966 non-null object\n",
      "Energy_Efficiency      267966 non-null object\n",
      "Instantaneous_Power    267966 non-null object\n",
      "Average_Power          267966 non-null object\n",
      "Normalised_Output      267966 non-null object\n",
      "Energy_Consumption     267966 non-null object\n",
      "Power_Consumption      267966 non-null object\n",
      "Temperature            267966 non-null object\n",
      "Voltage                267966 non-null object\n",
      "dtypes: object(11)\n",
      "memory usage: 22.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Energy_Generation</th>\n",
       "      <th>Energy_Efficiency</th>\n",
       "      <th>Instantaneous_Power</th>\n",
       "      <th>Average_Power</th>\n",
       "      <th>Normalised_Output</th>\n",
       "      <th>Energy_Consumption</th>\n",
       "      <th>Power_Consumption</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20121114</td>\n",
       "      <td>08:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20121114</td>\n",
       "      <td>09:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>0.028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20121114</td>\n",
       "      <td>09:10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.010</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20121114</td>\n",
       "      <td>09:20</td>\n",
       "      <td>23</td>\n",
       "      <td>0.021</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>0.067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20121114</td>\n",
       "      <td>09:30</td>\n",
       "      <td>38</td>\n",
       "      <td>0.035</td>\n",
       "      <td>96</td>\n",
       "      <td>90</td>\n",
       "      <td>0.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20121114</td>\n",
       "      <td>09:40</td>\n",
       "      <td>55</td>\n",
       "      <td>0.051</td>\n",
       "      <td>140</td>\n",
       "      <td>102</td>\n",
       "      <td>0.094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20121114</td>\n",
       "      <td>09:50</td>\n",
       "      <td>84</td>\n",
       "      <td>0.078</td>\n",
       "      <td>237</td>\n",
       "      <td>174</td>\n",
       "      <td>0.161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20121114</td>\n",
       "      <td>10:00</td>\n",
       "      <td>146</td>\n",
       "      <td>0.135</td>\n",
       "      <td>467</td>\n",
       "      <td>372</td>\n",
       "      <td>0.344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20121114</td>\n",
       "      <td>10:10</td>\n",
       "      <td>226</td>\n",
       "      <td>0.209</td>\n",
       "      <td>495</td>\n",
       "      <td>480</td>\n",
       "      <td>0.444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20121114</td>\n",
       "      <td>10:20</td>\n",
       "      <td>311</td>\n",
       "      <td>0.288</td>\n",
       "      <td>519</td>\n",
       "      <td>510</td>\n",
       "      <td>0.472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20121114</td>\n",
       "      <td>10:30</td>\n",
       "      <td>400</td>\n",
       "      <td>0.370</td>\n",
       "      <td>545</td>\n",
       "      <td>534</td>\n",
       "      <td>0.494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20121114</td>\n",
       "      <td>10:40</td>\n",
       "      <td>493</td>\n",
       "      <td>0.456</td>\n",
       "      <td>571</td>\n",
       "      <td>558</td>\n",
       "      <td>0.517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20121114</td>\n",
       "      <td>10:50</td>\n",
       "      <td>589</td>\n",
       "      <td>0.545</td>\n",
       "      <td>589</td>\n",
       "      <td>576</td>\n",
       "      <td>0.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20121114</td>\n",
       "      <td>11:00</td>\n",
       "      <td>689</td>\n",
       "      <td>0.638</td>\n",
       "      <td>606</td>\n",
       "      <td>600</td>\n",
       "      <td>0.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20121114</td>\n",
       "      <td>11:10</td>\n",
       "      <td>792</td>\n",
       "      <td>0.733</td>\n",
       "      <td>622</td>\n",
       "      <td>618</td>\n",
       "      <td>0.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Time Energy_Generation Energy_Efficiency Instantaneous_Power  \\\n",
       "0   20121114  08:50                 0             0.000                  26   \n",
       "1   20121114  09:00                 5             0.005                  32   \n",
       "2   20121114  09:10                11             0.010                  46   \n",
       "3   20121114  09:20                23             0.021                  80   \n",
       "4   20121114  09:30                38             0.035                  96   \n",
       "5   20121114  09:40                55             0.051                 140   \n",
       "6   20121114  09:50                84             0.078                 237   \n",
       "7   20121114  10:00               146             0.135                 467   \n",
       "8   20121114  10:10               226             0.209                 495   \n",
       "9   20121114  10:20               311             0.288                 519   \n",
       "10  20121114  10:30               400             0.370                 545   \n",
       "11  20121114  10:40               493             0.456                 571   \n",
       "12  20121114  10:50               589             0.545                 589   \n",
       "13  20121114  11:00               689             0.638                 606   \n",
       "14  20121114  11:10               792             0.733                 622   \n",
       "\n",
       "   Average_Power Normalised_Output Energy_Consumption Power_Consumption  \\\n",
       "0            NaN               NaN                NaN               NaN   \n",
       "1             30             0.028                NaN               NaN   \n",
       "2             36             0.033                NaN               NaN   \n",
       "3             72             0.067                NaN               NaN   \n",
       "4             90             0.083                NaN               NaN   \n",
       "5            102             0.094                NaN               NaN   \n",
       "6            174             0.161                NaN               NaN   \n",
       "7            372             0.344                NaN               NaN   \n",
       "8            480             0.444                NaN               NaN   \n",
       "9            510             0.472                NaN               NaN   \n",
       "10           534             0.494                NaN               NaN   \n",
       "11           558             0.517                NaN               NaN   \n",
       "12           576             0.533                NaN               NaN   \n",
       "13           600             0.556                NaN               NaN   \n",
       "14           618             0.572                NaN               NaN   \n",
       "\n",
       "   Temperature Voltage  \n",
       "0          5.8     NaN  \n",
       "1          5.8     NaN  \n",
       "2          5.8     NaN  \n",
       "3          6.1     NaN  \n",
       "4          6.1     NaN  \n",
       "5          6.1     NaN  \n",
       "6          7.2     NaN  \n",
       "7          7.2     NaN  \n",
       "8          7.2     NaN  \n",
       "9          8.4     NaN  \n",
       "10         8.4     NaN  \n",
       "11         8.4     NaN  \n",
       "12         9.8     NaN  \n",
       "13         9.8     NaN  \n",
       "14         9.8     NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test du call à l'API pour cette url \n",
    "TEST_CALL_API(\n",
    "    detail_PRODUCTION_url, \n",
    "    colonnes = detail_PRODUCTION_data_colonnes_l)\n",
    "\n",
    "# Chargement / Instanciation des df :\n",
    "(detail_PRODUCTION_log_df, detail_PRODUCTION_data_df) = CHARGEMENT_DONNEES_DISQUE(\n",
    "    detail_PRODUCTION_path, \n",
    "    detail_PRODUCTION_file_name_core,\n",
    "    detail_PRODUCTION_logs_colonnes_l, \n",
    "    detail_PRODUCTION_data_colonnes_l\n",
    ")\n",
    "\n",
    "# Instanciation de la liste des dates manquantes :\n",
    "detail_PRODUCTION_dates_requetes_l = FUNC_DATES_TO_CALL(\n",
    "    detail_PRODUCTION_log_df)\n",
    "\n",
    "# Call de l'API pr les dates manquantes : \n",
    "(detail_PRODUCTION_log_df, detail_PRODUCTION_data_df) = FUNC_CALL_API_JOUR(\n",
    "    detail_PRODUCTION_dates_requetes_l, \n",
    "    wait, \n",
    "    detail_PRODUCTION_url, \n",
    "    detail_PRODUCTION_log_df, \n",
    "    detail_PRODUCTION_data_df)\n",
    "\n",
    "# Enregistrement sur disque :\n",
    "FUNC_ENREGISTREMENT_DISQUE(\n",
    "    detail_PRODUCTION_path, \n",
    "    detail_PRODUCTION_file_name_core, \n",
    "    detail_PRODUCTION_log_df, \n",
    "    detail_PRODUCTION_data_df)\n",
    "\n",
    "# Check du dataset dispo :\n",
    "CHECK_DF(detail_PRODUCTION_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Détail_INSOLATION\n",
    "\n",
    "Détail de l'insolation d'un jour (getinsolation).\n",
    "Résolution temporelle de 5min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour \"Détails Insolation\"\n",
    "\n",
    "# Divers\n",
    "detail_INSOLATION_path = \"./DETAIL_INSOLATION/\" #Attention à ce fichu / en fin de path ;)\n",
    "detail_INSOLATION_file_name_core = \"detail_INSOLATION\"\n",
    "detail_INSOLATION_logs_colonnes_l = [\"TS_Call\", \"Date_cible\", \"Réponse\"]\n",
    "detail_INSOLATION_data_colonnes_l  = [\"Time\", \"Power\", \"Energy\", \"Date\"] #Il faut injecter manuellement la date, comme le call ne peut porter que sur une journée cible, c'est omis ds la réponse !\n",
    "\n",
    "# URL \n",
    "#Pas de paramètres interessants\n",
    "detail_INSOLATION_url = 'https://pvoutput.org/service/r2/getinsolation.jsp?'+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08:45</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08:50</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08:55</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09:00</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1  2\n",
       "0  08:40   0  0\n",
       "1  08:45   5  0\n",
       "2  08:50  18  2\n",
       "3  08:55  35  5\n",
       "4  09:00  54  9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier ./DETAIL_INSOLATION/ : trouvé\n",
      "Fichier detail_INSOLATION_log.pkl : trouvé et chargé \n",
      "Fichier detail_INSOLATION_data.pkl : trouvé et chargé \n",
      "Il y a déjà 2358 dates d'obtenues sur 2438, soit encore 80 dates a obtenir\n",
      "Traiter ce batch prendra 0.29 heures\n",
      "Dates en cours: de  20190430 \t 200\n",
      "Dates en cours: de  20190501 \t 200\n",
      "Dates en cours: de  20190502 \t 200\n",
      "Dates en cours: de  20190503 \t 200\n",
      "Dates en cours: de  20190504 \t 200\n",
      "Dates en cours: de  20190505 \t 200\n",
      "Dates en cours: de  20190506 \t 200\n",
      "Dates en cours: de  20190507 \t 200\n",
      "Dates en cours: de  20190508 \t 200\n",
      "Dates en cours: de  20190509 \t 200\n",
      "Dates en cours: de  20190510 \t 200\n",
      "Dates en cours: de  20190511 \t 200\n",
      "Dates en cours: de  20190512 \t 200\n",
      "Dates en cours: de  20190513 \t 200\n",
      "Dates en cours: de  20190514 \t 200\n",
      "Dates en cours: de  20190515 \t 200\n",
      "Dates en cours: de  20190516 \t 200\n",
      "Dates en cours: de  20190517 \t 200\n",
      "Dates en cours: de  20190518 \t 200\n",
      "Dates en cours: de  20190519 \t 200\n",
      "Dates en cours: de  20190520 \t 200\n",
      "Dates en cours: de  20190521 \t 200\n",
      "Dates en cours: de  20190522 \t 200\n",
      "Dates en cours: de  20190523 \t 200\n",
      "Dates en cours: de  20190524 \t 200\n",
      "Dates en cours: de  20190525 \t 200\n",
      "Dates en cours: de  20190526 \t 200\n",
      "Dates en cours: de  20190527 \t 200\n",
      "Dates en cours: de  20190528 \t 200\n",
      "Dates en cours: de  20190529 \t 200\n",
      "Dates en cours: de  20190530 \t 200\n",
      "Dates en cours: de  20190531 \t 200\n",
      "Dates en cours: de  20190601 \t 200\n",
      "Dates en cours: de  20190602 \t 200\n",
      "Dates en cours: de  20190603 \t 200\n",
      "Dates en cours: de  20190604 \t 200\n",
      "Dates en cours: de  20190605 \t 200\n",
      "Dates en cours: de  20190606 \t 200\n",
      "Dates en cours: de  20190607 \t 200\n",
      "Dates en cours: de  20190608 \t 200\n",
      "Dates en cours: de  20190609 \t 200\n",
      "Dates en cours: de  20190610 \t 200\n",
      "Dates en cours: de  20190611 \t 200\n",
      "Dates en cours: de  20190612 \t 200\n",
      "Dates en cours: de  20190613 \t 200\n",
      "Dates en cours: de  20190614 \t 200\n",
      "Dates en cours: de  20190615 \t 200\n",
      "Dates en cours: de  20190616 \t 200\n",
      "Dates en cours: de  20190617 \t 200\n",
      "Dates en cours: de  20190618 \t 200\n",
      "Dates en cours: de  20190619 \t 200\n",
      "Dates en cours: de  20190620 \t 200\n",
      "Dates en cours: de  20190621 \t 200\n",
      "Dates en cours: de  20190622 \t 200\n",
      "Dates en cours: de  20190623 \t 200\n",
      "Dates en cours: de  20190624 \t 200\n",
      "Dates en cours: de  20190625 \t 200\n",
      "Dates en cours: de  20190626 \t 200\n",
      "Dates en cours: de  20190627 \t 200\n",
      "Dates en cours: de  20190628 \t 200\n",
      "Dates en cours: de  20190629 \t 200\n",
      "Dates en cours: de  20190630 \t 200\n",
      "Dates en cours: de  20190701 \t 200\n",
      "Dates en cours: de  20190702 \t 200\n",
      "Dates en cours: de  20190703 \t 200\n",
      "Dates en cours: de  20190704 \t 200\n",
      "Dates en cours: de  20190705 \t 200\n",
      "Dates en cours: de  20190706 \t 200\n",
      "Dates en cours: de  20190707 \t 200\n",
      "Dates en cours: de  20190708 \t 200\n",
      "Dates en cours: de  20190709 \t 200\n",
      "Dates en cours: de  20190710 \t 200\n",
      "Dates en cours: de  20190711 \t 200\n",
      "Dates en cours: de  20190712 \t 200\n",
      "Dates en cours: de  20190713 \t 200\n",
      "Dates en cours: de  20190714 \t 200\n",
      "Dates en cours: de  20190715 \t 200\n",
      "Dates en cours: de  20190716 \t 200\n",
      "Dates en cours: de  20190717 \t 200\n",
      "Dates en cours: de  20190718 \t 200\n",
      "Fichiers enregistrés\n",
      "nb de ligne :  326383\n",
      "nb de ligne en doublons :  0 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 326383 entries, 0 to 326382\n",
      "Data columns (total 4 columns):\n",
      "Time      326383 non-null object\n",
      "Power     326383 non-null object\n",
      "Energy    326383 non-null object\n",
      "Date      326383 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 10.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Power</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08:05</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08:10</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08:15</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08:20</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08:25</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>08:30</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>08:35</td>\n",
       "      <td>113</td>\n",
       "      <td>33</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>08:40</td>\n",
       "      <td>133</td>\n",
       "      <td>44</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>08:45</td>\n",
       "      <td>153</td>\n",
       "      <td>57</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>08:50</td>\n",
       "      <td>173</td>\n",
       "      <td>71</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>08:55</td>\n",
       "      <td>192</td>\n",
       "      <td>87</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>09:00</td>\n",
       "      <td>212</td>\n",
       "      <td>105</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>09:05</td>\n",
       "      <td>231</td>\n",
       "      <td>124</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>09:10</td>\n",
       "      <td>250</td>\n",
       "      <td>145</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time Power Energy      Date\n",
       "0   08:00     0      0  20121114\n",
       "1   08:05     6      1  20121114\n",
       "2   08:10    19      2  20121114\n",
       "3   08:15    35      5  20121114\n",
       "4   08:20    54     10  20121114\n",
       "5   08:25    73     16  20121114\n",
       "6   08:30    93     23  20121114\n",
       "7   08:35   113     33  20121114\n",
       "8   08:40   133     44  20121114\n",
       "9   08:45   153     57  20121114\n",
       "10  08:50   173     71  20121114\n",
       "11  08:55   192     87  20121114\n",
       "12  09:00   212    105  20121114\n",
       "13  09:05   231    124  20121114\n",
       "14  09:10   250    145  20121114"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test du call à l'API pour cette url \n",
    "TEST_CALL_API(\n",
    "    detail_INSOLATION_url, \n",
    "    colonnes = detail_INSOLATION_data_colonnes_l)\n",
    "\n",
    "# Chargement / Instanciation des df :\n",
    "(detail_INSOLATION_log_df, detail_INSOLATION_data_df) = CHARGEMENT_DONNEES_DISQUE(\n",
    "    detail_INSOLATION_path, \n",
    "    detail_INSOLATION_file_name_core,\n",
    "    detail_INSOLATION_logs_colonnes_l, \n",
    "    detail_INSOLATION_data_colonnes_l)\n",
    "\n",
    "# Instanciation de la liste des dates manquantes :\n",
    "detail_INSOLATION_dates_requetes_l = FUNC_DATES_TO_CALL(\n",
    "    detail_INSOLATION_log_df)\n",
    "\n",
    "# Call de l'API pr les dates manquantes : \n",
    "(detail_INSOLATION_log_df, detail_INSOLATION_data_df) = FUNC_CALL_API_JOUR(\n",
    "    detail_INSOLATION_dates_requetes_l, \n",
    "    wait, \n",
    "    detail_INSOLATION_url, \n",
    "    detail_INSOLATION_log_df, \n",
    "    detail_INSOLATION_data_df)\n",
    "\n",
    "# Enregistrement sur disque :\n",
    "FUNC_ENREGISTREMENT_DISQUE(\n",
    "    detail_INSOLATION_path, \n",
    "    detail_INSOLATION_file_name_core,\n",
    "    detail_INSOLATION_log_df, \n",
    "    detail_INSOLATION_data_df)\n",
    "\n",
    "# Check du dataset dispo :\n",
    "CHECK_DF(\n",
    "    detail_INSOLATION_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Aggrég_PRODUCTION\n",
    "\n",
    "Set de valeurs aggrégées de la production sur une journée (getoutput).\n",
    "Résolution temporelle de 1j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo :\n",
    "- Charger valeurs fichiers (pas réellement besoin, mais pr faire propre)\n",
    "- Mettre aux propres les arguments des fonctions (celles de débug actuellement présentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour \"Détails Insolation\"\n",
    "\n",
    "# Divers\n",
    "aggreg_PRODUCTION_path = \"./AGGREGATION_PRODUCTION/\" #Attention à ce fichu / en fin de path ;)\n",
    "aggreg_PRODUCTION_file_name_core = \"aggreg_PRODUCTION\"\n",
    "aggreg_PRODUCTION_logs_colonnes_l = [\"TS_Call\", \"Date_Début_Période\", \"Date_Fin_Période\", \"Nb_j\", \"Réponse\"]\n",
    "aggreg_PRODUCTION_data_colonnes_l  = [\"Date\", \"Energy_Generated\", \"Efficiency\", \"Energy_Exported\", \"Energy_Used\", \"Peak_Power\", \"Peak_Time\", \"Condition\", \"Min_Temperature\", \"Max_Temperature\", \"Peak_Energy_Import\", \"Off-Peak_Energy_Import\", \"Shoulder_Energy_Import\", \"High-Shoulder_Energy_Import\", \"Insolation\"]\n",
    "\n",
    "# URL \n",
    "insolation = '&insolation=1'\n",
    "nb_max = '&limit=150' #C'est une limite de l'API pr ce call\n",
    "\n",
    "aggreg_PRODUCTION_url = 'https://pvoutput.org/service/r2/getoutput.jsp?'+insolation+nb_max+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb jours sur l'interval entier 2438\n",
      "nb de batch (de 150j) à envoyer 16.253333333333334\n"
     ]
    }
   ],
   "source": [
    "dates_l = list(pd.date_range(start= date_ancienne, end= pd.to_datetime('today'), freq='1D').strftime('%Y%m%d'))\n",
    "print(\"nb jours sur l'interval entier\", len(dates_l))\n",
    "print(\"nb de batch (de 150j) à envoyer\", len(dates_l) / 150)\n",
    "\n",
    "#ID_interval = 0\n",
    "#\n",
    "#for i in range(0, len(dates_l), 151):\n",
    "#    print(\"Soit l'intervale : \", ID_interval)\n",
    "#    ID_interval += 1\n",
    "#    \n",
    "#    if (i+150) < len(dates_l):\n",
    "#        print(\"début : \" + str(dates_l[i]) + \" fin : \" + str(dates_l[i+150]) + \" soit 150j\")\n",
    "#    else: \n",
    "#        print(\"début : \" + str(dates_l[i]) + \" fin : \" + str(dates_l[-1]) + \" soit \" + str(len(dates_l)-1-i) + \"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4a0bd2f197dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#Envois requête\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mrequete\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'&df='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdates_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'&dt='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Il semble que j'avais \"d\" au lieux de \"df\", erreur ou contournement ?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#Affichage live\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "log_df = pd.DataFrame(columns= aggreg_PRODUCTION_logs_colonnes_l)\n",
    "data_df = pd.DataFrame(columns= aggreg_PRODUCTION_data_colonnes_l)\n",
    "\n",
    "# Call API\n",
    "\n",
    "for i in range(0, len(dates_l), 151):\n",
    "    #Limitateur débit\n",
    "    time.sleep(wait) #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "    \n",
    "    # Routage pour dernière période \n",
    "    if (i+150) <= len(dates_l):\n",
    "        fin = dates_l[i+150]\n",
    "        nb_j = 150\n",
    "        \n",
    "    if (i+150) > len(dates_l):\n",
    "        fin = dates_l[-1]\n",
    "        nb_j = len(dates_l)-i\n",
    "    #<<Ajouter un catch d'erreur?\n",
    "\n",
    "    #Envois requête\n",
    "    requete = requests.get(url + '&df=' + dates_l[i] + '&dt=' + fin) #Il semble que j'avais \"d\" au lieux de \"df\", erreur ou contournement ?\n",
    "\n",
    "    #Affichage live\n",
    "    print(\"De {} à {} soit {} j, statut {} \".format(dates_l[i], fin, nb_j, requete.status_code))\n",
    "    \n",
    "    #Log des calls\n",
    "    log_df = log_df.append(\n",
    "        dict(\n",
    "            zip(\n",
    "                log_df.columns, #[\"TS_Call\", \"Date_Début_Période\", \"Date_Fin_Période\", \"Nb_j\", \"Réponse\"]\n",
    "                [pd.to_datetime('today'), dates_l[i], fin, nb_j, requete.status_code]\n",
    "            )\n",
    "        ), \n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "\n",
    "    for ligne in requete.text.split(';'):\n",
    "        #Append du df\n",
    "        data_df = data_df.append(\n",
    "            dict(\n",
    "                zip(\n",
    "                    data_df, \n",
    "                    ligne.split(',')\n",
    "                )\n",
    "            ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "data_df.sort_values(by='Date', inplace= True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement sur disque \n",
    "\n",
    "FUNC_ENREGISTREMENT_DISQUE(path, file_name_core, log_df, data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check des données\n",
    "\n",
    "CHECK_DF(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Info installation photovoiltaique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url info instalation\n",
    "\n",
    "detail = '&ext=1' \n",
    "sec_ar = '&array2=1'\n",
    "\n",
    "info_instalation_url = 'https://pvoutput.org/service/r2/getsystem.jsp?'+detail+sec_ar+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test requete instalation\n",
    "\n",
    "requests.get(info_instalation_url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
