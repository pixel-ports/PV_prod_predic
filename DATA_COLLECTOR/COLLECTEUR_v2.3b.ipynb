{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Synopsis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "PURPOSE :\n",
    "\n",
    "Aller récupérer sur l'API de PVOutput.org les données d'une station cible:\n",
    "- données production \"live\" (cad pas de temps de 5min à 10min sans la météo) ==> Detail_PROD\n",
    "- données d'insolation (cad pas de temps de 5min à 10min sans la météo. Pas complètement clair si correspond exactement extraterestrial radiation) ==> Detail_INSOL\n",
    "- données production quotidienne (somme sur la journée, dispo aussi en mensuel etc. Ajoute un champ (catégoriel) sur la couverture nuageuse) ==> Aggreg_PROD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "PRINCIPE :\n",
    "\n",
    "Traitement successif des 3 types de requêtes (avec en bonus les carac de l'installation)\n",
    "- Formulation et test de la requêtes\n",
    "- Définition des dates:\n",
    "    - Déterminer la liste des dates maximale\n",
    "    - A partir des logs, déterminer les dates pour lesquelles on a déjà les données\n",
    "    - Etablir la nouvelle liste de dates pour lesquelles on doit requêter (nouvelles dates ou erreurs)\n",
    "- Boucle de requêtes\n",
    "    - Charger le DF sur disque\n",
    "    - Envois requête\n",
    "    - Append des données reçues dans le DF\n",
    "- Exporter les résultat prk et csv)\n",
    "    - Logs\n",
    "    - Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "LOGS :\n",
    "v2.2 Ajout de la gestion des dates déjà téléchargés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "TODO : \n",
    "- le rappel des date dl ne fonctionne pas comme il faut\n",
    "- la borne haute des dates à appelée n'est pas call (exclusif au lieu d'inclusif)\n",
    "- appliquer la refactoriser en fonctions au autres url\n",
    "    - <<Attention ! pr les données aggrégées il va falloir reprendre des choses\n",
    "- convertir les types à la création des df\n",
    "- merge les dates et time en un TS ?\n",
    "\n",
    "- Gestion des limites d'API\n",
    "     - \"Rate limit information can be obtained by setting the HTTP header X-Rate-Limit to 1\" https://pvoutput.org/help.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Librairies et MeP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Librairie\n",
    "\n",
    "#Divers\n",
    "import requests #Call API\n",
    "import time #Pr avoir dates avec today etc\n",
    "import os #Pr création dossier etc\n",
    "import pandas as pd\n",
    "\n",
    "#Graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Mise en forme du notebook \n",
    "\n",
    "# Nb de ligne à afficher #Uniquement pr Jup Notbook ?\n",
    "# pd.options.display.max_rows=100 \n",
    "\n",
    "# Largeur des cellules #Uniquement pr Jup Notbook ?\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "# Mettre en output toutes les sortie d'une cellule\n",
    "from IPython.core.interactiveshell import InteractiveShell \n",
    "InteractiveShell.ast_node_interactivity = \"all\" #\"last_expr\"\n",
    "\n",
    "# Avoir une forme de débugger\n",
    "from IPython.core.debugger import Tracer # Plancer Tracer()() dans la fonction permet d'avoir un pas à pas, \"n(ext) line and run this one, c(ontinue) running until next breakpoint, q(uit) the debugger\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Paramètres globaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Paramètres génériques des requètes\n",
    "\n",
    "notre_sys_id = '&sid=66192'\n",
    "api_key = '&key=a29f3f9a012ea9da77c829911b595ae7c470362b'\n",
    "target_sys_id = '&sid1=13412'\n",
    "\n",
    "para_gene = notre_sys_id+api_key+target_sys_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Bornes dates"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Valeurs pr test (A INVERSER AVEC VALEURS PR PRODUCTION)\n",
    "\n",
    "wait = 1 #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "date_recente = pd.to_datetime('20121115', format=\"%Y%m%d\", errors='coerce')\n",
    "date_ancienne = pd.to_datetime('20121114', format=\"%Y%m%d\", errors='coerce') # C'est la première date à partir de laquelle des données exploitables existent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Valeurs pr production\n",
    "\n",
    "wait = 13 #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "date_recente = pd.to_datetime('today')\n",
    "date_ancienne = pd.to_datetime('20190401', format=\"%Y%m%d\", errors='coerce') # Ici date de la dernière MaJ (cad dl des nouvelles données). La première date à partir de laquelle des données exploitables existent est le 20121114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Définition des fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Test du call API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def TEST_CALL_API(url, date=\"20130101\", colonnes=[]):\n",
    "    ''' url, date(opt), colonnes(opt) --> df\n",
    "    url (url sans la date cible), \n",
    "    date (format texte, par défaut 20130101),\n",
    "    colonnes (liste de noms de colonnes)\n",
    "    '''\n",
    "    #Tracer()() \n",
    "    reponse_l = []\n",
    "    \n",
    "    for ligne in requests.get(url+'&d='+date).text.split(';'):\n",
    "        reponse_l.append(ligne.split(','))\n",
    "        \n",
    "    df = pd.DataFrame.from_records(reponse_l)\n",
    "    \n",
    "    if len(colonnes) == df.shape[1]:\n",
    "        df.columns = colonnes\n",
    "\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Instanciation (potenciellement par chargement des données déjà DL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def CHARGEMENT_DONNEES_DISQUE(path, file_name_core, logs_colonnes_l, data_colonnes_l):\n",
    "    '''(path, file_name_core) --> (log_df, data_df)\n",
    "    NB : si les fichiers ne sont pas trouvés, on instancie des df vierges, mais qui ne seront pas écris sur disque ici. Ce sera la fonction d'enregistrement, qui dans la même passe attribues des noms de colonnes\n",
    "    '''\n",
    "    # Dossier\n",
    "    if os.path.exists(path):\n",
    "        print(\"Dossier %s : trouvé\" % path)\n",
    "    else:\n",
    "        os.makedirs(path)\n",
    "        print(\"Dossier %s : non trouvé\" % path)\n",
    "\n",
    "    # Fichier de logs :\n",
    "    if os.path.isfile(path + file_name_core +\"_log.pkl\") and os.access(path + file_name_core + \"_log.pkl\", os.R_OK):\n",
    "        print(\"Fichier %s : trouvé et chargé \" % (file_name_core +\"_log.pkl\"))\n",
    "        log_df = pd.read_pickle(path + file_name_core + \"_log.pkl\")\n",
    "    else:\n",
    "        print(\"Fichier %s : non trouvé, un nouveau est instancié\" % (file_name_core +\"_log.pkl\"))\n",
    "        log_df = pd.DataFrame(columns= logs_colonnes_l)\n",
    "        \n",
    "\n",
    "    # Fichier de données :\n",
    "    if os.path.isfile(path + file_name_core +\"_data.pkl\") and os.access(path + file_name_core + \"_data.pkl\", os.R_OK):\n",
    "        print(\"Fichier %s : trouvé et chargé \" % (file_name_core +\"_data.pkl\"))\n",
    "        data_df = pd.read_pickle(path + file_name_core + \"_data.pkl\")\n",
    "    else:\n",
    "        print(\"Fichier %s : non trouvé, un nouveau est instancié\" % (file_name_core +\"_data.pkl\"))\n",
    "        data_df = pd.DataFrame(columns = data_colonnes_l)\n",
    "    \n",
    "    return (log_df, data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Création liste de dates à call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def FUNC_DATES_TO_CALL(log_df): #<<ATTENTION a adapter pr données de production aggrégées, dont la requête n'utilise pas la même forme de liste de date\n",
    "    '''log --> dates_requetes_l\n",
    "    '''\n",
    "    \n",
    "    # Instanciation de la liste de date (en str) à paser argument de la requête :\n",
    "    dates_possibles_l = pd.date_range(start= date_ancienne, end= date_recente).strftime('%Y%m%d')\n",
    "    dates_deja_obtenues_l = list(log_df.loc[log_df['Réponse'] == 200, 'Date_cible'])\n",
    "    dates_requetes_l = [date for date in dates_possibles_l if date not in dates_deja_obtenues_l]\n",
    "    #print(\"dates_possibles_l\", type(dates_possibles_l), dates_possibles_l) \n",
    "    #print(\"dates_deja_obtenues_l\", type(dates_deja_obtenues_l), dates_deja_obtenues_l)\n",
    "    #print(\"dates_requetes_l\", type(dates_requetes_l), dates_requetes_l)\n",
    "\n",
    "    # Calcul durée traitement (en heures)\n",
    "    print(\"Il y a déjà %d dates d'obtenues sur %d, soit encore %d dates a obtenir\" % (len(dates_deja_obtenues_l), len(dates_possibles_l), len(dates_requetes_l)))\n",
    "    print(\"Traiter ce batch prendra %.2f heures\" % ((len(dates_requetes_l)*wait)/(60*60)))\n",
    "    \n",
    "    return dates_requetes_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Call API en batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def FUNC_CALL_API_JOUR(dates_requetes_l, wait, url, log_df, data_df):\n",
    "    '''(dates_requetes_l, wait, url, log_df, data_df) --> (log_df, data_df) complétés\n",
    "    '''\n",
    "\n",
    "    for date in dates_requetes_l :\n",
    "        #Limitateur débit\n",
    "        time.sleep(wait) #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "\n",
    "        #Envois requête\n",
    "        requete = requests.get(url + '&d=' + date)\n",
    "        \n",
    "        #Affichage live\n",
    "        print(\"Dates en cours: de \", date, \"\\t\",requete.status_code)\n",
    "\n",
    "        #Log des calls\n",
    "        log_df = log_df.append(\n",
    "            dict(\n",
    "                zip(\n",
    "                    log_df.columns, \n",
    "                    [pd.to_datetime('today'), date, requete.status_code]\n",
    "                )\n",
    "            ), \n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "       #Controleur validité réponse\n",
    "        if requete.status_code == 200:\n",
    "            for ligne in requete.text.split(';'):\n",
    "                #Append du df\n",
    "                data_df = data_df.append(\n",
    "                    dict(\n",
    "                        zip(\n",
    "                            data_df, \n",
    "                            (ligne.split(',') + [date]) # Petite trick due à la requête pr l'insolation, qui ne renvoit pas la date (==> on force la présence de la colonne et ici sa valeur)\n",
    "                        )\n",
    "                    ),\n",
    "                    ignore_index=True\n",
    "                )\n",
    "            \n",
    "        \n",
    "    return (log_df, data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Enregistrement sur disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def FUNC_ENREGISTREMENT_DISQUE(path, file_name_core, log_df, data_df):\n",
    "    '''(path, file_name_core, log_df, data_df) --> Enregistrement de log_df et data_df en pkl et csv dans le dossier spécifié\n",
    "    '''\n",
    "    # Logs\n",
    "    log_df.to_pickle(path + file_name_core + \"_log.pkl\")\n",
    "    log_df.to_csv(path + file_name_core + \"_log.csv\", index= False)\n",
    "    \n",
    "    # Df\n",
    "    data_df.to_pickle(path + file_name_core + \"_data.pkl\")\n",
    "    data_df.to_csv(path + file_name_core + \"_data.csv\", index= False)\n",
    "    \n",
    "    print(\"Fichiers enregistrés\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Check du df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def CHECK_DF(df):\n",
    "    '''df --> Nb de lignes, nb de lignes en double, df.info() et df.head(15) \n",
    "    '''\n",
    "    print(\"nb de ligne : \", len(df))\n",
    "    print(\"nb de ligne en doublons : \", df.duplicated().sum(), \"\\n\")\n",
    "    \n",
    "    df.info()\n",
    "    return df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Set de valeur pour débugage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#Jeu de variable pr le débugage\n",
    "\n",
    "path = detail_INSOLATION_path\n",
    "file_name_core = detail_INSOLATION_file_name_core\n",
    "logs_colonnes_l = detail_INSOLATION_logs_colonnes_l\n",
    "data_colonnes_l = detail_INSOLATION_data_colonnes_l \n",
    "url = detail_INSOLATION_url"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Test du call à l'API pour cette url \n",
    "\n",
    "TEST_CALL_API(url, colonnes = data_colonnes_l)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Chargement des données\n",
    "\n",
    "(log_df, data_df) = CHARGEMENT_DONNEES_DISQUE(path, file_name_core, logs_colonnes_l, data_colonnes_l)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Liste des dates à call\n",
    "\n",
    "dates_requetes_l = FUNC_DATES_TO_CALL(log_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Call API\n",
    "\n",
    "(log_df, data_df) = FUNC_CALL_API_JOUR(dates_requetes_l, wait, url, log_df, data_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Enregistrement sur disque \n",
    "\n",
    "FUNC_ENREGISTREMENT_DISQUE(path, file_name_core, log_df, data_df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Check des données\n",
    "\n",
    "CHECK_DF(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Détail_PRODUCTION\n",
    "\n",
    "Détail de la production d'un jour (getstatus).\n",
    "Résolution temporelle de 10min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Paramètres pour \"Détails Production\"\n",
    "\n",
    "# Divers\n",
    "detail_PRODUCTION_path = \"./DETAIL_PRODUCTION/\" #Attention à ce fichu / en fin de path ;)\n",
    "detail_PRODUCTION_file_name_core = \"detail_PRODUCTION\"\n",
    "detail_PRODUCTION_logs_colonnes_l = [\"TS_Call\", \"Date_cible\", \"Réponse\"]\n",
    "detail_PRODUCTION_data_colonnes_l  = [\"Date\", \"Time\", \"Energy_Generation\", \"Energy_Efficiency\", \"Instantaneous_Power\", \"Average_Power\", \"Normalised_Output\", \"Energy_Consumption\", \"Power_Consumption\", \"Temperature\", \"Voltage\"] #/ The parameter sid1 is able to retrieve generation data from any system. Consumption data is not returned. The requesting system must have donation mode enabled. \n",
    "\n",
    "# URL\n",
    "detail = '&h=1' #The history parameter returns the entire status for a given date. \n",
    "nb_max = '&limit=288' #Besoin de fixer à la valeur max de 288\n",
    "ordre = '&asc=1'\n",
    "detail_PRODUCTION_url = 'https://pvoutput.org/service/r2/getstatus.jsp?'+detail+nb_max+ordre+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['20121114,08:50,0,0.000,26,NaN,NaN,NaN,NaN,5.8,NaN',\n",
       " '20121114,09:00,5,0.005,32,30,0.028,NaN,NaN,5.8,NaN',\n",
       " '20121114,09:10,11,0.010,46,36,0.033,NaN,NaN,5.8,NaN',\n",
       " '20121114,09:20,23,0.021,80,72,0.067,NaN,NaN,6.1,NaN',\n",
       " '20121114,09:30,38,0.035,96,90,0.083,NaN,NaN,6.1,NaN',\n",
       " '20121114,09:40,55,0.051,140,102,0.094,NaN,NaN,6.1,NaN',\n",
       " '20121114,09:50,84,0.078,237,174,0.161,NaN,NaN,7.2,NaN',\n",
       " '20121114,10:00,146,0.135,467,372,0.344,NaN,NaN,7.2,NaN',\n",
       " '20121114,10:10,226,0.209,495,480,0.444,NaN,NaN,7.2,NaN',\n",
       " '20121114,10:20,311,0.288,519,510,0.472,NaN,NaN,8.4,NaN',\n",
       " '20121114,10:30,400,0.370,545,534,0.494,NaN,NaN,8.4,NaN',\n",
       " '20121114,10:40,493,0.456,571,558,0.517,NaN,NaN,8.4,NaN',\n",
       " '20121114,10:50,589,0.545,589,576,0.533,NaN,NaN,9.8,NaN',\n",
       " '20121114,11:00,689,0.638,606,600,0.556,NaN,NaN,9.8,NaN',\n",
       " '20121114,11:10,792,0.733,622,618,0.572,NaN,NaN,9.8,NaN',\n",
       " '20121114,11:20,897,0.831,631,630,0.583,NaN,NaN,12.2,NaN',\n",
       " '20121114,11:30,1003,0.929,639,636,0.589,NaN,NaN,12.2,NaN',\n",
       " '20121114,11:40,1112,1.030,661,654,0.606,NaN,NaN,12.2,NaN',\n",
       " '20121114,11:50,1223,1.132,665,666,0.617,NaN,NaN,12.2,NaN',\n",
       " '20121114,12:10,1446,1.339,671,669,0.619,NaN,NaN,14.4,NaN',\n",
       " '20121114,12:20,1558,1.443,678,672,0.622,NaN,NaN,14.4,NaN',\n",
       " '20121114,12:30,1672,1.548,677,684,0.633,NaN,NaN,16.3,NaN',\n",
       " '20121114,12:40,1785,1.653,674,678,0.628,NaN,NaN,16.3,NaN',\n",
       " '20121114,12:50,1898,1.757,671,678,0.628,NaN,NaN,16.3,NaN',\n",
       " '20121114,13:00,2010,1.861,671,672,0.622,NaN,NaN,17.6,NaN',\n",
       " '20121114,13:10,2122,1.965,663,672,0.622,NaN,NaN,17.6,NaN',\n",
       " '20121114,13:20,2232,2.067,657,660,0.611,NaN,NaN,17.6,NaN',\n",
       " '20121114,13:30,2341,2.168,654,654,0.606,NaN,NaN,19.0,NaN',\n",
       " '20121114,13:40,2450,2.269,652,654,0.606,NaN,NaN,19.0,NaN',\n",
       " '20121114,13:50,2558,2.369,657,648,0.600,NaN,NaN,19.0,NaN',\n",
       " '20121114,14:00,2669,2.471,687,666,0.617,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:10,2785,2.579,689,696,0.644,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:20,2873,2.660,252,528,0.489,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:30,2912,2.696,156,234,0.217,NaN,NaN,20.4,NaN',\n",
       " '20121114,14:40,2974,2.754,530,372,0.344,NaN,NaN,19.7,NaN',\n",
       " '20121114,14:50,3023,2.799,194,294,0.272,NaN,NaN,19.7,NaN',\n",
       " '20121114,15:00,3055,2.829,176,192,0.178,NaN,NaN,19.7,NaN',\n",
       " '20121114,15:10,3079,2.851,118,144,0.133,NaN,NaN,18.9,NaN',\n",
       " '20121114,15:20,3100,2.870,100,126,0.117,NaN,NaN,18.9,NaN',\n",
       " '20121114,15:30,3124,2.893,205,144,0.133,NaN,NaN,18.9,NaN',\n",
       " '20121114,15:40,3180,2.944,373,336,0.311,NaN,NaN,18.0,NaN',\n",
       " '20121114,15:50,3240,3.000,341,360,0.333,NaN,NaN,18.0,NaN',\n",
       " '20121114,16:00,3293,3.049,303,318,0.294,NaN,NaN,18.0,NaN',\n",
       " '20121114,16:10,3341,3.094,267,288,0.267,NaN,NaN,18.0,NaN',\n",
       " '20121114,16:20,3382,3.131,222,246,0.228,NaN,NaN,17.6,NaN',\n",
       " '20121114,16:30,3417,3.164,184,210,0.194,NaN,NaN,17.6,NaN',\n",
       " '20121114,16:40,3444,3.189,137,162,0.150,NaN,NaN,17.6,NaN',\n",
       " '20121114,16:50,3462,3.206,90,108,0.100,NaN,NaN,17.0,NaN',\n",
       " '20121114,17:00,3474,3.217,42,72,0.067,NaN,NaN,17.0,NaN',\n",
       " '20121114,17:10,3476,3.219,4,12,0.011,NaN,NaN,17.0,NaN']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "reponse = requests.get(detail_PRODUCTION_url+'&d='+\"20121114\")\n",
    "reponse.status_code\n",
    "reponse.text.split(';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Traitement du batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Energy_Generation</th>\n",
       "      <th>Energy_Efficiency</th>\n",
       "      <th>Instantaneous_Power</th>\n",
       "      <th>Average_Power</th>\n",
       "      <th>Normalised_Output</th>\n",
       "      <th>Energy_Consumption</th>\n",
       "      <th>Power_Consumption</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20130101</td>\n",
       "      <td>10:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20130101</td>\n",
       "      <td>10:10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.004</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20130101</td>\n",
       "      <td>10:20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.009</td>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20130101</td>\n",
       "      <td>10:30</td>\n",
       "      <td>19</td>\n",
       "      <td>0.018</td>\n",
       "      <td>70</td>\n",
       "      <td>54</td>\n",
       "      <td>0.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20130101</td>\n",
       "      <td>10:40</td>\n",
       "      <td>27</td>\n",
       "      <td>0.025</td>\n",
       "      <td>34</td>\n",
       "      <td>48</td>\n",
       "      <td>0.044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date   Time Energy_Generation Energy_Efficiency Instantaneous_Power  \\\n",
       "0  20130101  10:00                 0             0.000                  25   \n",
       "1  20130101  10:10                 4             0.004                  25   \n",
       "2  20130101  10:20                10             0.009                  52   \n",
       "3  20130101  10:30                19             0.018                  70   \n",
       "4  20130101  10:40                27             0.025                  34   \n",
       "\n",
       "  Average_Power Normalised_Output Energy_Consumption Power_Consumption  \\\n",
       "0           NaN               NaN                NaN               NaN   \n",
       "1            24             0.022                NaN               NaN   \n",
       "2            36             0.033                NaN               NaN   \n",
       "3            54             0.050                NaN               NaN   \n",
       "4            48             0.044                NaN               NaN   \n",
       "\n",
       "  Temperature Voltage  \n",
       "0         8.6     NaN  \n",
       "1         8.9     NaN  \n",
       "2         8.9     NaN  \n",
       "3         8.9     NaN  \n",
       "4         9.5     NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier ./DETAIL_PRODUCTION/ : trouvé\n",
      "Fichier detail_PRODUCTION_log.pkl : trouvé et chargé \n",
      "Fichier detail_PRODUCTION_data.pkl : trouvé et chargé \n",
      "Il y a déjà 2387 dates d'obtenues sur 166, soit encore 57 dates a obtenir\n",
      "Traiter ce batch prendra 0.21 heures\n",
      "Dates en cours: de  20190719 \t 200\n",
      "Dates en cours: de  20190720 \t 200\n",
      "Dates en cours: de  20190721 \t 200\n",
      "Dates en cours: de  20190722 \t 200\n",
      "Dates en cours: de  20190723 \t 200\n",
      "Dates en cours: de  20190724 \t 200\n",
      "Dates en cours: de  20190725 \t 200\n",
      "Dates en cours: de  20190726 \t 200\n",
      "Dates en cours: de  20190727 \t 200\n",
      "Dates en cours: de  20190728 \t 200\n",
      "Dates en cours: de  20190729 \t 200\n",
      "Dates en cours: de  20190730 \t 200\n",
      "Dates en cours: de  20190731 \t 200\n",
      "Dates en cours: de  20190801 \t 200\n",
      "Dates en cours: de  20190802 \t 200\n",
      "Dates en cours: de  20190803 \t 200\n",
      "Dates en cours: de  20190804 \t 200\n",
      "Dates en cours: de  20190805 \t 200\n",
      "Dates en cours: de  20190806 \t 200\n",
      "Dates en cours: de  20190807 \t 200\n",
      "Dates en cours: de  20190808 \t 200\n",
      "Dates en cours: de  20190809 \t 200\n",
      "Dates en cours: de  20190810 \t 200\n",
      "Dates en cours: de  20190811 \t 200\n",
      "Dates en cours: de  20190812 \t 200\n",
      "Dates en cours: de  20190813 \t 200\n",
      "Dates en cours: de  20190814 \t 200\n",
      "Dates en cours: de  20190815 \t 200\n",
      "Dates en cours: de  20190816 \t 200\n",
      "Dates en cours: de  20190817 \t 200\n",
      "Dates en cours: de  20190818 \t 200\n",
      "Dates en cours: de  20190819 \t 200\n",
      "Dates en cours: de  20190820 \t 200\n",
      "Dates en cours: de  20190821 \t 200\n",
      "Dates en cours: de  20190822 \t 200\n",
      "Dates en cours: de  20190823 \t 200\n",
      "Dates en cours: de  20190824 \t 200\n",
      "Dates en cours: de  20190825 \t 200\n",
      "Dates en cours: de  20190826 \t 200\n",
      "Dates en cours: de  20190827 \t 200\n",
      "Dates en cours: de  20190828 \t 200\n",
      "Dates en cours: de  20190829 \t 200\n",
      "Dates en cours: de  20190830 \t 200\n",
      "Dates en cours: de  20190831 \t 200\n",
      "Dates en cours: de  20190901 \t 200\n",
      "Dates en cours: de  20190902 \t 200\n",
      "Dates en cours: de  20190903 \t 200\n",
      "Dates en cours: de  20190904 \t 200\n",
      "Dates en cours: de  20190905 \t 200\n",
      "Dates en cours: de  20190906 \t 200\n",
      "Dates en cours: de  20190907 \t 200\n",
      "Dates en cours: de  20190908 \t 200\n",
      "Dates en cours: de  20190909 \t 200\n",
      "Dates en cours: de  20190910 \t 200\n",
      "Dates en cours: de  20190911 \t 200\n",
      "Dates en cours: de  20190912 \t 200\n",
      "Dates en cours: de  20190913 \t 200\n",
      "Fichiers enregistrés\n",
      "nb de ligne :  276655\n",
      "nb de ligne en doublons :  0 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276655 entries, 0 to 276654\n",
      "Data columns (total 11 columns):\n",
      "Date                   276655 non-null object\n",
      "Time                   276655 non-null object\n",
      "Energy_Generation      276655 non-null object\n",
      "Energy_Efficiency      276655 non-null object\n",
      "Instantaneous_Power    276655 non-null object\n",
      "Average_Power          276655 non-null object\n",
      "Normalised_Output      276655 non-null object\n",
      "Energy_Consumption     276655 non-null object\n",
      "Power_Consumption      276655 non-null object\n",
      "Temperature            276655 non-null object\n",
      "Voltage                276655 non-null object\n",
      "dtypes: object(11)\n",
      "memory usage: 23.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Energy_Generation</th>\n",
       "      <th>Energy_Efficiency</th>\n",
       "      <th>Instantaneous_Power</th>\n",
       "      <th>Average_Power</th>\n",
       "      <th>Normalised_Output</th>\n",
       "      <th>Energy_Consumption</th>\n",
       "      <th>Power_Consumption</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Voltage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20121114</td>\n",
       "      <td>08:50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20121114</td>\n",
       "      <td>09:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>0.028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20121114</td>\n",
       "      <td>09:10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.010</td>\n",
       "      <td>46</td>\n",
       "      <td>36</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20121114</td>\n",
       "      <td>09:20</td>\n",
       "      <td>23</td>\n",
       "      <td>0.021</td>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>0.067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20121114</td>\n",
       "      <td>09:30</td>\n",
       "      <td>38</td>\n",
       "      <td>0.035</td>\n",
       "      <td>96</td>\n",
       "      <td>90</td>\n",
       "      <td>0.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>20121114</td>\n",
       "      <td>09:40</td>\n",
       "      <td>55</td>\n",
       "      <td>0.051</td>\n",
       "      <td>140</td>\n",
       "      <td>102</td>\n",
       "      <td>0.094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>20121114</td>\n",
       "      <td>09:50</td>\n",
       "      <td>84</td>\n",
       "      <td>0.078</td>\n",
       "      <td>237</td>\n",
       "      <td>174</td>\n",
       "      <td>0.161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>20121114</td>\n",
       "      <td>10:00</td>\n",
       "      <td>146</td>\n",
       "      <td>0.135</td>\n",
       "      <td>467</td>\n",
       "      <td>372</td>\n",
       "      <td>0.344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20121114</td>\n",
       "      <td>10:10</td>\n",
       "      <td>226</td>\n",
       "      <td>0.209</td>\n",
       "      <td>495</td>\n",
       "      <td>480</td>\n",
       "      <td>0.444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20121114</td>\n",
       "      <td>10:20</td>\n",
       "      <td>311</td>\n",
       "      <td>0.288</td>\n",
       "      <td>519</td>\n",
       "      <td>510</td>\n",
       "      <td>0.472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20121114</td>\n",
       "      <td>10:30</td>\n",
       "      <td>400</td>\n",
       "      <td>0.370</td>\n",
       "      <td>545</td>\n",
       "      <td>534</td>\n",
       "      <td>0.494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>20121114</td>\n",
       "      <td>10:40</td>\n",
       "      <td>493</td>\n",
       "      <td>0.456</td>\n",
       "      <td>571</td>\n",
       "      <td>558</td>\n",
       "      <td>0.517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20121114</td>\n",
       "      <td>10:50</td>\n",
       "      <td>589</td>\n",
       "      <td>0.545</td>\n",
       "      <td>589</td>\n",
       "      <td>576</td>\n",
       "      <td>0.533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20121114</td>\n",
       "      <td>11:00</td>\n",
       "      <td>689</td>\n",
       "      <td>0.638</td>\n",
       "      <td>606</td>\n",
       "      <td>600</td>\n",
       "      <td>0.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20121114</td>\n",
       "      <td>11:10</td>\n",
       "      <td>792</td>\n",
       "      <td>0.733</td>\n",
       "      <td>622</td>\n",
       "      <td>618</td>\n",
       "      <td>0.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Time Energy_Generation Energy_Efficiency Instantaneous_Power  \\\n",
       "0   20121114  08:50                 0             0.000                  26   \n",
       "1   20121114  09:00                 5             0.005                  32   \n",
       "2   20121114  09:10                11             0.010                  46   \n",
       "3   20121114  09:20                23             0.021                  80   \n",
       "4   20121114  09:30                38             0.035                  96   \n",
       "5   20121114  09:40                55             0.051                 140   \n",
       "6   20121114  09:50                84             0.078                 237   \n",
       "7   20121114  10:00               146             0.135                 467   \n",
       "8   20121114  10:10               226             0.209                 495   \n",
       "9   20121114  10:20               311             0.288                 519   \n",
       "10  20121114  10:30               400             0.370                 545   \n",
       "11  20121114  10:40               493             0.456                 571   \n",
       "12  20121114  10:50               589             0.545                 589   \n",
       "13  20121114  11:00               689             0.638                 606   \n",
       "14  20121114  11:10               792             0.733                 622   \n",
       "\n",
       "   Average_Power Normalised_Output Energy_Consumption Power_Consumption  \\\n",
       "0            NaN               NaN                NaN               NaN   \n",
       "1             30             0.028                NaN               NaN   \n",
       "2             36             0.033                NaN               NaN   \n",
       "3             72             0.067                NaN               NaN   \n",
       "4             90             0.083                NaN               NaN   \n",
       "5            102             0.094                NaN               NaN   \n",
       "6            174             0.161                NaN               NaN   \n",
       "7            372             0.344                NaN               NaN   \n",
       "8            480             0.444                NaN               NaN   \n",
       "9            510             0.472                NaN               NaN   \n",
       "10           534             0.494                NaN               NaN   \n",
       "11           558             0.517                NaN               NaN   \n",
       "12           576             0.533                NaN               NaN   \n",
       "13           600             0.556                NaN               NaN   \n",
       "14           618             0.572                NaN               NaN   \n",
       "\n",
       "   Temperature Voltage  \n",
       "0          5.8     NaN  \n",
       "1          5.8     NaN  \n",
       "2          5.8     NaN  \n",
       "3          6.1     NaN  \n",
       "4          6.1     NaN  \n",
       "5          6.1     NaN  \n",
       "6          7.2     NaN  \n",
       "7          7.2     NaN  \n",
       "8          7.2     NaN  \n",
       "9          8.4     NaN  \n",
       "10         8.4     NaN  \n",
       "11         8.4     NaN  \n",
       "12         9.8     NaN  \n",
       "13         9.8     NaN  \n",
       "14         9.8     NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test du call à l'API pour cette url \n",
    "TEST_CALL_API(\n",
    "    detail_PRODUCTION_url, \n",
    "    colonnes = detail_PRODUCTION_data_colonnes_l)\n",
    "\n",
    "# Chargement / Instanciation des df :\n",
    "(detail_PRODUCTION_log_df, detail_PRODUCTION_data_df) = CHARGEMENT_DONNEES_DISQUE(\n",
    "    detail_PRODUCTION_path, \n",
    "    detail_PRODUCTION_file_name_core,\n",
    "    detail_PRODUCTION_logs_colonnes_l, \n",
    "    detail_PRODUCTION_data_colonnes_l\n",
    ")\n",
    "\n",
    "# Instanciation de la liste des dates manquantes :\n",
    "detail_PRODUCTION_dates_requetes_l = FUNC_DATES_TO_CALL(\n",
    "    detail_PRODUCTION_log_df)\n",
    "\n",
    "# Call de l'API pr les dates manquantes : \n",
    "(detail_PRODUCTION_log_df, detail_PRODUCTION_data_df) = FUNC_CALL_API_JOUR(\n",
    "    detail_PRODUCTION_dates_requetes_l, \n",
    "    wait, \n",
    "    detail_PRODUCTION_url, \n",
    "    detail_PRODUCTION_log_df, \n",
    "    detail_PRODUCTION_data_df)\n",
    "\n",
    "# Enregistrement sur disque :\n",
    "FUNC_ENREGISTREMENT_DISQUE(\n",
    "    detail_PRODUCTION_path, \n",
    "    detail_PRODUCTION_file_name_core, \n",
    "    detail_PRODUCTION_log_df, \n",
    "    detail_PRODUCTION_data_df)\n",
    "\n",
    "# Check du dataset dispo :\n",
    "CHECK_DF(detail_PRODUCTION_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Détail_INSOLATION\n",
    "\n",
    "Détail de l'insolation d'un jour (getinsolation).\n",
    "Résolution temporelle de 5min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Paramètres pour \"Détails Insolation\"\n",
    "\n",
    "# Divers\n",
    "detail_INSOLATION_path = \"./DETAIL_INSOLATION/\" #Attention à ce fichu / en fin de path ;)\n",
    "detail_INSOLATION_file_name_core = \"detail_INSOLATION\"\n",
    "detail_INSOLATION_logs_colonnes_l = [\"TS_Call\", \"Date_cible\", \"Réponse\"]\n",
    "detail_INSOLATION_data_colonnes_l  = [\"Time\", \"Power\", \"Energy\", \"Date\"] #Il faut injecter manuellement la date, comme le call ne peut porter que sur une journée cible, c'est omis ds la réponse !\n",
    "\n",
    "# URL \n",
    "#Pas de paramètres interessants\n",
    "detail_INSOLATION_url = 'https://pvoutput.org/service/r2/getinsolation.jsp?'+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>08:40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>08:45</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>08:50</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>08:55</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>09:00</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1  2\n",
       "0  08:40   0  0\n",
       "1  08:45   5  0\n",
       "2  08:50  18  2\n",
       "3  08:55  35  5\n",
       "4  09:00  54  9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier ./DETAIL_INSOLATION/ : trouvé\n",
      "Fichier detail_INSOLATION_log.pkl : trouvé et chargé \n",
      "Fichier detail_INSOLATION_data.pkl : trouvé et chargé \n",
      "Il y a déjà 2438 dates d'obtenues sur 166, soit encore 57 dates a obtenir\n",
      "Traiter ce batch prendra 0.21 heures\n",
      "Dates en cours: de  20190719 \t 200\n",
      "Dates en cours: de  20190720 \t 200\n",
      "Dates en cours: de  20190721 \t 200\n",
      "Dates en cours: de  20190722 \t 200\n",
      "Dates en cours: de  20190723 \t 200\n",
      "Dates en cours: de  20190724 \t 200\n",
      "Dates en cours: de  20190725 \t 200\n",
      "Dates en cours: de  20190726 \t 200\n",
      "Dates en cours: de  20190727 \t 200\n",
      "Dates en cours: de  20190728 \t 200\n",
      "Dates en cours: de  20190729 \t 200\n",
      "Dates en cours: de  20190730 \t 200\n",
      "Dates en cours: de  20190731 \t 200\n",
      "Dates en cours: de  20190801 \t 200\n",
      "Dates en cours: de  20190802 \t 200\n",
      "Dates en cours: de  20190803 \t 200\n",
      "Dates en cours: de  20190804 \t 200\n",
      "Dates en cours: de  20190805 \t 200\n",
      "Dates en cours: de  20190806 \t 200\n",
      "Dates en cours: de  20190807 \t 200\n",
      "Dates en cours: de  20190808 \t 200\n",
      "Dates en cours: de  20190809 \t 200\n",
      "Dates en cours: de  20190810 \t 200\n",
      "Dates en cours: de  20190811 \t 200\n",
      "Dates en cours: de  20190812 \t 200\n",
      "Dates en cours: de  20190813 \t 200\n",
      "Dates en cours: de  20190814 \t 200\n",
      "Dates en cours: de  20190815 \t 200\n",
      "Dates en cours: de  20190816 \t 200\n",
      "Dates en cours: de  20190817 \t 200\n",
      "Dates en cours: de  20190818 \t 200\n",
      "Dates en cours: de  20190819 \t 200\n",
      "Dates en cours: de  20190820 \t 200\n",
      "Dates en cours: de  20190821 \t 200\n",
      "Dates en cours: de  20190822 \t 200\n",
      "Dates en cours: de  20190823 \t 200\n",
      "Dates en cours: de  20190824 \t 200\n",
      "Dates en cours: de  20190825 \t 200\n",
      "Dates en cours: de  20190826 \t 200\n",
      "Dates en cours: de  20190827 \t 200\n",
      "Dates en cours: de  20190828 \t 200\n",
      "Dates en cours: de  20190829 \t 200\n",
      "Dates en cours: de  20190830 \t 200\n",
      "Dates en cours: de  20190831 \t 200\n",
      "Dates en cours: de  20190901 \t 200\n",
      "Dates en cours: de  20190902 \t 200\n",
      "Dates en cours: de  20190903 \t 200\n",
      "Dates en cours: de  20190904 \t 200\n",
      "Dates en cours: de  20190905 \t 200\n",
      "Dates en cours: de  20190906 \t 200\n",
      "Dates en cours: de  20190907 \t 200\n",
      "Dates en cours: de  20190908 \t 200\n",
      "Dates en cours: de  20190909 \t 200\n",
      "Dates en cours: de  20190910 \t 200\n",
      "Dates en cours: de  20190911 \t 200\n",
      "Dates en cours: de  20190912 \t 200\n",
      "Dates en cours: de  20190913 \t 200\n",
      "Fichiers enregistrés\n",
      "nb de ligne :  334740\n",
      "nb de ligne en doublons :  0 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334740 entries, 0 to 334739\n",
      "Data columns (total 4 columns):\n",
      "Time      334740 non-null object\n",
      "Power     334740 non-null object\n",
      "Energy    334740 non-null object\n",
      "Date      334740 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 10.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Power</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>08:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>08:05</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>08:10</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>08:15</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>08:20</td>\n",
       "      <td>54</td>\n",
       "      <td>10</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>08:25</td>\n",
       "      <td>73</td>\n",
       "      <td>16</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>08:30</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>08:35</td>\n",
       "      <td>113</td>\n",
       "      <td>33</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>08:40</td>\n",
       "      <td>133</td>\n",
       "      <td>44</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>08:45</td>\n",
       "      <td>153</td>\n",
       "      <td>57</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>08:50</td>\n",
       "      <td>173</td>\n",
       "      <td>71</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>08:55</td>\n",
       "      <td>192</td>\n",
       "      <td>87</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>09:00</td>\n",
       "      <td>212</td>\n",
       "      <td>105</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>09:05</td>\n",
       "      <td>231</td>\n",
       "      <td>124</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>09:10</td>\n",
       "      <td>250</td>\n",
       "      <td>145</td>\n",
       "      <td>20121114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time Power Energy      Date\n",
       "0   08:00     0      0  20121114\n",
       "1   08:05     6      1  20121114\n",
       "2   08:10    19      2  20121114\n",
       "3   08:15    35      5  20121114\n",
       "4   08:20    54     10  20121114\n",
       "5   08:25    73     16  20121114\n",
       "6   08:30    93     23  20121114\n",
       "7   08:35   113     33  20121114\n",
       "8   08:40   133     44  20121114\n",
       "9   08:45   153     57  20121114\n",
       "10  08:50   173     71  20121114\n",
       "11  08:55   192     87  20121114\n",
       "12  09:00   212    105  20121114\n",
       "13  09:05   231    124  20121114\n",
       "14  09:10   250    145  20121114"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test du call à l'API pour cette url \n",
    "TEST_CALL_API(\n",
    "    detail_INSOLATION_url, \n",
    "    colonnes = detail_INSOLATION_data_colonnes_l)\n",
    "\n",
    "# Chargement / Instanciation des df :\n",
    "(detail_INSOLATION_log_df, detail_INSOLATION_data_df) = CHARGEMENT_DONNEES_DISQUE(\n",
    "    detail_INSOLATION_path, \n",
    "    detail_INSOLATION_file_name_core,\n",
    "    detail_INSOLATION_logs_colonnes_l, \n",
    "    detail_INSOLATION_data_colonnes_l)\n",
    "\n",
    "# Instanciation de la liste des dates manquantes :\n",
    "detail_INSOLATION_dates_requetes_l = FUNC_DATES_TO_CALL(\n",
    "    detail_INSOLATION_log_df)\n",
    "\n",
    "# Call de l'API pr les dates manquantes : \n",
    "(detail_INSOLATION_log_df, detail_INSOLATION_data_df) = FUNC_CALL_API_JOUR(\n",
    "    detail_INSOLATION_dates_requetes_l, \n",
    "    wait, \n",
    "    detail_INSOLATION_url, \n",
    "    detail_INSOLATION_log_df, \n",
    "    detail_INSOLATION_data_df)\n",
    "\n",
    "# Enregistrement sur disque :\n",
    "FUNC_ENREGISTREMENT_DISQUE(\n",
    "    detail_INSOLATION_path, \n",
    "    detail_INSOLATION_file_name_core,\n",
    "    detail_INSOLATION_log_df, \n",
    "    detail_INSOLATION_data_df)\n",
    "\n",
    "# Check du dataset dispo :\n",
    "CHECK_DF(\n",
    "    detail_INSOLATION_data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# Aggrég_PRODUCTION\n",
    "\n",
    "Set de valeurs aggrégées de la production sur une journée (getoutput).\n",
    "Résolution temporelle de 1j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Todo :\n",
    "- Charger valeurs fichiers (pas réellement besoin, mais pr faire propre)\n",
    "- Mettre aux propres les arguments des fonctions (celles de débug actuellement présentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Paramètres pour \"Détails Insolation\"\n",
    "\n",
    "# Divers\n",
    "aggreg_PRODUCTION_path = \"./AGGREGATION_PRODUCTION/\" #Attention à ce fichu / en fin de path ;)\n",
    "aggreg_PRODUCTION_file_name_core = \"aggreg_PRODUCTION\"\n",
    "aggreg_PRODUCTION_logs_colonnes_l = [\"TS_Call\", \"Date_Début_Période\", \"Date_Fin_Période\", \"Nb_j\", \"Réponse\"]\n",
    "aggreg_PRODUCTION_data_colonnes_l  = [\"Date\", \"Energy_Generated\", \"Efficiency\", \"Energy_Exported\", \"Energy_Used\", \"Peak_Power\", \"Peak_Time\", \"Condition\", \"Min_Temperature\", \"Max_Temperature\", \"Peak_Energy_Import\", \"Off-Peak_Energy_Import\", \"Shoulder_Energy_Import\", \"High-Shoulder_Energy_Import\", \"Insolation\"]\n",
    "\n",
    "# URL \n",
    "insolation = '&insolation=1'\n",
    "nb_max = '&limit=150' #C'est une limite de l'API pr ce call\n",
    "\n",
    "aggreg_PRODUCTION_url = 'https://pvoutput.org/service/r2/getoutput.jsp?'+insolation+nb_max+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb jours sur l'interval entier 166\n",
      "nb de batch (de 150j) à envoyer 1.1066666666666667\n"
     ]
    }
   ],
   "source": [
    "dates_l = list(pd.date_range(start= date_ancienne, end= pd.to_datetime('today'), freq='1D').strftime('%Y%m%d'))\n",
    "print(\"nb jours sur l'interval entier\", len(dates_l))\n",
    "print(\"nb de batch (de 150j) à envoyer\", len(dates_l) / 150)\n",
    "\n",
    "#ID_interval = 0\n",
    "#\n",
    "#for i in range(0, len(dates_l), 151):\n",
    "#    print(\"Soit l'intervale : \", ID_interval)\n",
    "#    ID_interval += 1\n",
    "#    \n",
    "#    if (i+150) < len(dates_l):\n",
    "#        print(\"début : \" + str(dates_l[i]) + \" fin : \" + str(dates_l[i+150]) + \" soit 150j\")\n",
    "#    else: \n",
    "#        print(\"début : \" + str(dates_l[i]) + \" fin : \" + str(dates_l[-1]) + \" soit \" + str(len(dates_l)-1-i) + \"j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De 20190401 à 20190829 soit 150 j, statut 200 \n",
      "De 20190830 à 20190913 soit 15 j, statut 200 \n"
     ]
    }
   ],
   "source": [
    "log_df = pd.DataFrame(columns= aggreg_PRODUCTION_logs_colonnes_l)\n",
    "data_df = pd.DataFrame(columns= aggreg_PRODUCTION_data_colonnes_l)\n",
    "\n",
    "# Call API\n",
    "\n",
    "for i in range(0, len(dates_l), 151):\n",
    "    #Limitateur débit\n",
    "    time.sleep(wait) #\"300 requests per hour in donation mode.\" soit un await minimun de 12s\n",
    "    \n",
    "    # Routage pour dernière période \n",
    "    if (i+150) <= len(dates_l):\n",
    "        fin = dates_l[i+150]\n",
    "        nb_j = 150\n",
    "        \n",
    "    if (i+150) > len(dates_l):\n",
    "        fin = dates_l[-1]\n",
    "        nb_j = len(dates_l)-i\n",
    "    #<<Ajouter un catch d'erreur?\n",
    "\n",
    "    #Envois requête\n",
    "    requete = requests.get(aggreg_PRODUCTION_url + '&df=' + dates_l[i] + '&dt=' + fin) #Il semble que j'avais \"d\" au lieux de \"df\", erreur ou contournement ?\n",
    "\n",
    "    #Affichage live\n",
    "    print(\"De {} à {} soit {} j, statut {} \".format(dates_l[i], fin, nb_j, requete.status_code))\n",
    "    \n",
    "    #Log des calls\n",
    "    log_df = log_df.append(\n",
    "        dict(\n",
    "            zip(\n",
    "                log_df.columns, #[\"TS_Call\", \"Date_Début_Période\", \"Date_Fin_Période\", \"Nb_j\", \"Réponse\"]\n",
    "                [pd.to_datetime('today'), dates_l[i], fin, nb_j, requete.status_code]\n",
    "            )\n",
    "        ), \n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "\n",
    "    for ligne in requete.text.split(';'):\n",
    "        #Append du df\n",
    "        data_df = data_df.append(\n",
    "            dict(\n",
    "                zip(\n",
    "                    data_df, \n",
    "                    ligne.split(',')\n",
    "                )\n",
    "            ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "data_df.sort_values(by='Date', inplace= True)  \n",
    "\n",
    "\n",
    "aggreg_PRODUCTION_log_df = log_df\n",
    "aggreg_PRODUCTION_data_df = data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TS_Call</th>\n",
       "      <th>Date_Début_Période</th>\n",
       "      <th>Date_Fin_Période</th>\n",
       "      <th>Nb_j</th>\n",
       "      <th>Réponse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-09-13 17:57:40.278113</td>\n",
       "      <td>20190401</td>\n",
       "      <td>20190829</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-09-13 17:57:54.424015</td>\n",
       "      <td>20190830</td>\n",
       "      <td>20190913</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TS_Call Date_Début_Période Date_Fin_Période Nb_j Réponse\n",
       "0 2019-09-13 17:57:40.278113           20190401         20190829  150     200\n",
       "1 2019-09-13 17:57:54.424015           20190830         20190913   15     200"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers enregistrés\n"
     ]
    }
   ],
   "source": [
    "# Enregistrement sur disque \n",
    "\n",
    "FUNC_ENREGISTREMENT_DISQUE(aggreg_PRODUCTION_path, aggreg_PRODUCTION_file_name_core, aggreg_PRODUCTION_log_df, aggreg_PRODUCTION_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb de ligne :  165\n",
      "nb de ligne en doublons :  0 \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165 entries, 149 to 150\n",
      "Data columns (total 15 columns):\n",
      "Date                           165 non-null object\n",
      "Energy_Generated               165 non-null object\n",
      "Efficiency                     165 non-null object\n",
      "Energy_Exported                165 non-null object\n",
      "Energy_Used                    165 non-null object\n",
      "Peak_Power                     165 non-null object\n",
      "Peak_Time                      165 non-null object\n",
      "Condition                      165 non-null object\n",
      "Min_Temperature                165 non-null object\n",
      "Max_Temperature                165 non-null object\n",
      "Peak_Energy_Import             165 non-null object\n",
      "Off-Peak_Energy_Import         165 non-null object\n",
      "Shoulder_Energy_Import         165 non-null object\n",
      "High-Shoulder_Energy_Import    165 non-null object\n",
      "Insolation                     165 non-null object\n",
      "dtypes: object(15)\n",
      "memory usage: 20.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Energy_Generated</th>\n",
       "      <th>Efficiency</th>\n",
       "      <th>Energy_Exported</th>\n",
       "      <th>Energy_Used</th>\n",
       "      <th>Peak_Power</th>\n",
       "      <th>Peak_Time</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Min_Temperature</th>\n",
       "      <th>Max_Temperature</th>\n",
       "      <th>Peak_Energy_Import</th>\n",
       "      <th>Off-Peak_Energy_Import</th>\n",
       "      <th>Shoulder_Energy_Import</th>\n",
       "      <th>High-Shoulder_Energy_Import</th>\n",
       "      <th>Insolation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>20190402</td>\n",
       "      <td>2121</td>\n",
       "      <td>1.964</td>\n",
       "      <td>1857</td>\n",
       "      <td>0</td>\n",
       "      <td>975</td>\n",
       "      <td>15:05</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>20190403</td>\n",
       "      <td>1330</td>\n",
       "      <td>1.231</td>\n",
       "      <td>1170</td>\n",
       "      <td>0</td>\n",
       "      <td>692</td>\n",
       "      <td>17:25</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>20190404</td>\n",
       "      <td>5119</td>\n",
       "      <td>4.740</td>\n",
       "      <td>4497</td>\n",
       "      <td>0</td>\n",
       "      <td>928</td>\n",
       "      <td>14:50</td>\n",
       "      <td>Fine</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>20190405</td>\n",
       "      <td>3329</td>\n",
       "      <td>3.082</td>\n",
       "      <td>3130</td>\n",
       "      <td>0</td>\n",
       "      <td>910</td>\n",
       "      <td>13:50</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>20190406</td>\n",
       "      <td>2390</td>\n",
       "      <td>2.213</td>\n",
       "      <td>2136</td>\n",
       "      <td>0</td>\n",
       "      <td>833</td>\n",
       "      <td>16:20</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>20190407</td>\n",
       "      <td>2815</td>\n",
       "      <td>2.606</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "      <td>1067</td>\n",
       "      <td>15:05</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>20190408</td>\n",
       "      <td>1754</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1613</td>\n",
       "      <td>0</td>\n",
       "      <td>875</td>\n",
       "      <td>12:05</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>20190409</td>\n",
       "      <td>4172</td>\n",
       "      <td>3.863</td>\n",
       "      <td>3616</td>\n",
       "      <td>0</td>\n",
       "      <td>967</td>\n",
       "      <td>14:35</td>\n",
       "      <td>Fine</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>20190410</td>\n",
       "      <td>3123</td>\n",
       "      <td>2.892</td>\n",
       "      <td>2651</td>\n",
       "      <td>0</td>\n",
       "      <td>1014</td>\n",
       "      <td>13:30</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>20190411</td>\n",
       "      <td>1970</td>\n",
       "      <td>1.824</td>\n",
       "      <td>1581</td>\n",
       "      <td>0</td>\n",
       "      <td>923</td>\n",
       "      <td>12:35</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>20190412</td>\n",
       "      <td>4725</td>\n",
       "      <td>4.375</td>\n",
       "      <td>4688</td>\n",
       "      <td>0</td>\n",
       "      <td>866</td>\n",
       "      <td>13:20</td>\n",
       "      <td>Fine</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>20190413</td>\n",
       "      <td>5630</td>\n",
       "      <td>5.213</td>\n",
       "      <td>5158</td>\n",
       "      <td>0</td>\n",
       "      <td>802</td>\n",
       "      <td>13:40</td>\n",
       "      <td>Fine</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>20190414</td>\n",
       "      <td>1513</td>\n",
       "      <td>1.401</td>\n",
       "      <td>1266</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>15:35</td>\n",
       "      <td>Cloudy</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>20190415</td>\n",
       "      <td>3070</td>\n",
       "      <td>2.843</td>\n",
       "      <td>2601</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>11:55</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>20190416</td>\n",
       "      <td>2360</td>\n",
       "      <td>2.185</td>\n",
       "      <td>1879</td>\n",
       "      <td>0</td>\n",
       "      <td>1048</td>\n",
       "      <td>12:40</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Energy_Generated Efficiency Energy_Exported Energy_Used  \\\n",
       "149  20190402             2121      1.964            1857           0   \n",
       "148  20190403             1330      1.231            1170           0   \n",
       "147  20190404             5119      4.740            4497           0   \n",
       "146  20190405             3329      3.082            3130           0   \n",
       "145  20190406             2390      2.213            2136           0   \n",
       "144  20190407             2815      2.606            1900           0   \n",
       "143  20190408             1754      1.624            1613           0   \n",
       "142  20190409             4172      3.863            3616           0   \n",
       "141  20190410             3123      2.892            2651           0   \n",
       "140  20190411             1970      1.824            1581           0   \n",
       "139  20190412             4725      4.375            4688           0   \n",
       "138  20190413             5630      5.213            5158           0   \n",
       "137  20190414             1513      1.401            1266           0   \n",
       "136  20190415             3070      2.843            2601           0   \n",
       "135  20190416             2360      2.185            1879           0   \n",
       "\n",
       "    Peak_Power Peak_Time      Condition Min_Temperature Max_Temperature  \\\n",
       "149        975     15:05  Mostly Cloudy               9              19   \n",
       "148        692     17:25         Cloudy               5              10   \n",
       "147        928     14:50           Fine               7              17   \n",
       "146        910     13:50  Partly Cloudy               2              21   \n",
       "145        833     16:20  Mostly Cloudy               4              17   \n",
       "144       1067     15:05  Partly Cloudy               5              18   \n",
       "143        875     12:05  Mostly Cloudy               5              20   \n",
       "142        967     14:35           Fine               5              22   \n",
       "141       1014     13:30  Partly Cloudy               4              20   \n",
       "140        923     12:35  Mostly Cloudy               4              17   \n",
       "139        866     13:20           Fine               6              21   \n",
       "138        802     13:40           Fine               0              23   \n",
       "137        520     15:35         Cloudy               3              18   \n",
       "136        709     11:55  Partly Cloudy               4              25   \n",
       "135       1048     12:40  Mostly Cloudy               9              19   \n",
       "\n",
       "    Peak_Energy_Import Off-Peak_Energy_Import Shoulder_Energy_Import  \\\n",
       "149                NaN                    NaN                    NaN   \n",
       "148                NaN                    NaN                    NaN   \n",
       "147                NaN                    NaN                    NaN   \n",
       "146                NaN                    NaN                    NaN   \n",
       "145                NaN                    NaN                    NaN   \n",
       "144                NaN                    NaN                    NaN   \n",
       "143                NaN                    NaN                    NaN   \n",
       "142                NaN                    NaN                    NaN   \n",
       "141                NaN                    NaN                    NaN   \n",
       "140                NaN                    NaN                    NaN   \n",
       "139                NaN                    NaN                    NaN   \n",
       "138                NaN                    NaN                    NaN   \n",
       "137                NaN                    NaN                    NaN   \n",
       "136                NaN                    NaN                    NaN   \n",
       "135                NaN                    NaN                    NaN   \n",
       "\n",
       "    High-Shoulder_Energy_Import Insolation  \n",
       "149                         NaN       5995  \n",
       "148                         NaN       6014  \n",
       "147                         NaN       6033  \n",
       "146                         NaN       6052  \n",
       "145                         NaN       6070  \n",
       "144                         NaN       6087  \n",
       "143                         NaN       6104  \n",
       "142                         NaN       6120  \n",
       "141                         NaN       6135  \n",
       "140                         NaN       6150  \n",
       "139                         NaN       6165  \n",
       "138                         NaN       6179  \n",
       "137                         NaN       6192  \n",
       "136                         NaN       6205  \n",
       "135                         NaN       6218  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check des données\n",
    "\n",
    "CHECK_DF(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Info installation photovoiltaique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# url info instalation\n",
    "\n",
    "detail = '&ext=1' \n",
    "sec_ar = '&array2=1'\n",
    "\n",
    "info_instalation_url = 'https://pvoutput.org/service/r2/getsystem.jsp?'+detail+sec_ar+para_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#Test requete instalation\n",
    "\n",
    "requests.get(info_instalation_url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
